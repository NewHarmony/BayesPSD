{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How To Search for QPOs with BayesPSD\n",
    "\n",
    "This notebook is a demonstration for how to use the code in this package\n",
    "to search for quasi-periodic oscillations (QPOs) in X-ray data of bursts.\n",
    "\n",
    "This code requires\n",
    "* python 2.7 or later (not really tested with python 3)\n",
    "* numpy\n",
    "* scipy\n",
    "* matplotlib\n",
    "\n",
    "Recommended\n",
    "* emcee (https://github.com/dfm/emcee)\n",
    "* acor (https://github.com/dfm/acor)\n",
    "* statsmodels (https://github.com/statsmodels/statsmodels; only for using crazy minimization algorithms that don't return the inverse covariance)\n",
    "* seaborn for making pretty plots (http://stanford.edu/~mwaskom/software/seaborn/)\n",
    "\n",
    "## Basics\n",
    "\n",
    "The module contains both the code to do Bayesian inference on bursty time series, as well \n",
    "as some basic class definitions that are useful for time series analysis in general, and for\n",
    "*Fermi*/GBM data in particular.\n",
    "\n",
    "Let's start with a simple time series in a data file. This is actually a magnetar bursts from \n",
    "a source called SGR J1550-5418, but that's not important right now. \n",
    "I've made things easy for you here: the data are individual photon events and energies only from \n",
    "the part of the observation where the burst was observed. We'll have a look at more complicated \n",
    "data and how to automate the steps outlined below later.\n",
    "\n",
    "For now, let's import some code and load the time series.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "## this is just to make plots prettier\n",
    "## comment out if you don't have seaborn\n",
    "import seaborn as sns \n",
    "sns.set()\n",
    "########################################\n",
    "\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**NOTE**: You need to have the directory where you saved the BayesPSD code in your `PYTHONPATH` variable for the following to work! If you haven't set your variable externally, you can do it in the following way:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/Users/danielahuppenkothen/work/repositories/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Be aware that you need to replace the directory structure with your own, and that you need to add the path to the directory in which the BayesPSD folder is located. In my case, that's in my `repositories` folder in my work directory on my home folder, but it will be different for you!\n",
    "Also, when importing below, `bayespsd` needs to be written exactly as the name of the folder (it's case sensitive!). \n",
    "\n",
    "Now we can import functions and classes from that package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from BayesPSD import Lightcurve, PowerSpectrum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data are saved in a simple text file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape : (13001, 2)\n"
     ]
    }
   ],
   "source": [
    "## the directory where we've stored the data\n",
    "datadir = \"../data/\" \n",
    "\n",
    "data = np.loadtxt(datadir+\"090122283_+071.87300_eventfile.dat\")\n",
    "print(\"Data shape : \" + str(data.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is a numpy-array with 130001 rows and 2 columns. Each row is a photon, the first column contains the photon arrival times, the second column the energies.\n",
    "\n",
    "For now, let's not care about the energies (don't worry, we'll get back to that later!).\n",
    "Let's make a light curve and plot it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x112223590>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAewAAAFVCAYAAAAt79zdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJztnXmgHFWZ9p/q5fZdc7Pd7CSBhFRIIAlhJ8OOCAyLOio4\nuCAKKqh8jBsw6oyjjowLjow4KIjiLiqirINCIBDWkI2QpLLv201y96XX+v6orupT1VXdVX27u3p5\nfv/c7urq6nO7qus573veRVJVFYQQQgipbAJ+D4AQQggh+aFgE0IIIVUABZsQQgipAijYhBBCSBVA\nwSaEEEKqAAo2IYQQUgWE8u0gy/IZAO5SFOUCWZYXAbgHQBJAFMCHFUU5JMvyjQBuApAA8A1FUZ4o\n5aAJIYSQeiOnhS3L8hcB3A8gkt703wA+rSjKBQAeAfAlWZYnAvgMgLMBvBPAt2RZbijdkAkhhJD6\nI59LfAuA9wCQ0s+vVRRlbfpxGMAQgNMBLFcUJa4oSm/6PQtKMVhCCCGkXskp2IqiPALNza0/PwAA\nsiyfDeAWAN8HMApAj/C2PgDtRR8pIYQQUsfkXcO2IsvyNQDuBHC5oihHZFnuBdAm7NIGoCvXMRKJ\npBoKBb1+NCGEEFLNSPl3ccaTYMuy/EFowWXnK4qii/LrAL4py3IEQCOAEwCsy3Wcrq7BAoZaeXR0\ntKGzs8/vYRDwXFQSPBeVBc9H5dDR0ZZ/pxy4FWxVluUAgB8A2AngEVmWAeB5RVG+JsvyPQBehOZi\nv1NRlNiIRkUIIYQQE3kFW1GUHdAiwAFgnMM+DwB4oHjDIoQQQogIC6cQQgghVQAFmxBCCKkCKNiE\nEEJIFUDBJoQQQqoACjYhhBBSBVCwCSGEkCqAgk0IIYRUARRsQkhVMTgcRzyR8nsYhJQdCjYhpKr4\n9H+/iC/d97LfwyCk7FCwCSFVg6qqAIDuflY/JvUHBZsQUjUkU6rfQyDENyjYhJCqIZmkYJP6hYJN\nCKkakikGm5H6hYJNCKkaEnSJkzqGgk0IqRroEif1DAWbEFI10CVO6hkKNiGkamCUOKlnKNiEkKqB\nLnFSz1CwCSFVAy1sUs9QsAkhVQPXsEk9Q8EmhFQNdImTeoaCTQipGugSJ/UMBZsQUjUkk3SJk/qF\ngk0IqRpoYZN6hoJNCKkaWJqU1DMUbEJI1cCgM1LPULAJIVUD07pIPUPBJoRUDSm6xEkdQ8EmhFQN\nDDoj9QwFmxBSNVCwST1DwSaE+E40lkQsnsy7H/OwST1DwSaE+M6n7n4Bt3x/Wd79mNZF6hkKNiGk\nInDj7mZaF6lnKNiEkIohn1ucaV2knqFgE0Iqhp6BWM7XmdZF6hkKNiGkYujpzy3YKvWa1DEUbEJI\nxdDdH835eoqKTeoYCjYhpGIYiib8HgIhFQsFmxBSMQznCTrjEjapZyjYhJCKYTiWW7BVusRJHUPB\nJoT4iijC0byCXerREFK5ULAJIb4iinBewQYVm9QvFGxCiK+Ikd/DsdxBZ7SwST0TyreDLMtnALhL\nUZQLZFmeDeDnAFIA1gG4RVEUVZblGwHcBCAB4BuKojxRwjETQmoIsRhKvqAzrmGTeianhS3L8hcB\n3A8gkt50N4A7FUU5F4AE4GpZlicB+AyAswG8E8C3ZFluKN2QCSG1RIpr2IS4Ip9LfAuA90ATZwBY\nrCiK3lLnKQAXAzgNwHJFUeKKovSm37OgFIMlhNQeYnnwfFHiLJxC6pmcgq0oyiPQ3Nw6kvC4D0A7\ngFEAemy2E0JIXsxr2Hl6YlOvSR2Tdw3bgtgqZxSAbgC9ANqE7W0AunIdZMyYZoRCQY8fXZl0dLTl\n34mUBZ6LysHLuWgQypGqUHO+t7ExXNBn1Dv8rmoDr4K9Spbl8xRFeQHAZQCeBfA6gG/KshwB0Ajg\nBGgBaY50dQ0WMtaKo6OjDZ2dfX4Pg4DnopLwei56BMGOx1M53zswlGkOwvPtDv42KoeRTpzcCrbu\niPocgPvTQWXrAfwxHSV+D4AXobnY71QUJXfLHUIISSOWG823Rs0lbFLP5BVsRVF2QIsAh6IomwGc\nb7PPAwAeKPLYCCF1gJjWlTdti4pN6hgWTiGE+Ioo0vmae7D5B6lnKNiEEF9JmQQ7n0ucik3qFwo2\nIcRXRKtZzWNCU69JPUPBJoT4iriGnc/lTQub1DMUbEKIr4hu8HyCTLkm9QwFmxDiK2YLm2vYhDhB\nwSaE+IpqysN2vy/Fm9QbFGxCiK+YXOJ5FNu0b8lGREhlQsEmhPiK6BKPJVK44a7nsPfwQP43UrFJ\nnUHBJoT4it269bLV+xz2zTxWqdikzqBgE0J8xW4pempHi8O+YkR5qUZESGVCwSaE+ErKZt06GJBs\n9zUHnZVqRIRUJhRsQoiv2LnEndK7zJHhVGxSX1CwCSG+YifOTtYzLWxSz1CwCSG+kkplb0s6pHep\nTOsidQwFmxDiK7YucSfBFh/TxCZ1BgWbEOIrdsVSnNawU4wSJ3UMBZsQ4iteLGz6wUk9Q8EmhPiK\nnTa7iRKnhU3qDQo2IcRX7KxpJwublc5IPUPBJoT4in0etv2+tLBJPUPBJoT4il20t2OUOEWa1DEU\nbEKIr9jlYTOti5BsKNiEEF8ptDQp9ZrUGxRsQoiv9A3Gsra5cYlTr0m9QcEmhPjKzoP9AICJY5qM\nba6af9DEJnUGBZsQ4iu7D/WjpTGEMW0RY5vdujZgWcMu7bAIqTgo2IQQX4nGEmhtCpu2ObvEuYZN\n6hcKNiHEV1QVgCSZBNi5lrj4Pio2qS8o2IQQX1FVFQHJ7OJ2tYZNSJ1BwSaE+IpmYEsmH7dTP2ww\n5ozUMRRsQoivqCogWSxsu5abAF3ipL6hYBNCfEVVVUhwt4YtNvygXJN6g4JNCPGVlGFh53eJV3vh\nlFg8iZfX7Uc0nvR7KKQKoWATQnxFVVVIEkwK7KZbVzUuYj+ybBseeHwDHnlhm99DIVUIBZsQ4it6\n0JlpfbpGLext+3oBAHsP9/s8ElKNULAJIb6ip3WJEvzmpk4c6hq03TfzuAyDKzLxpFbCLRTkrZd4\nh1cNIcRXtChxKUuA/7p8h+2+mcfVp9iJtGCHKdikAHjVEEJ8RYsSz3Zx21mhTtHj1UIikbawQ7z1\nEu/wqiGE+IpuYVsVO5xH1KpRuxOGS1zyeSSkGqFgE0J8xSicYlFgO8E2r2FXn2LHk9qY6RInhcCr\nhhDiK1paV7bFaSdqqSqPEtdd4kEKNikAXjWEEN9QVa1cirX5B5Dfwq5GxWbQGRkJIa9vkGU5DOAh\nADMAJAHcmP77cwApAOsA3KIoShX+nAgh5cRUP9zi4rYLOqtyvc6kdYW4hk28U8g073IAQUVRlgD4\nDwD/CeB7AO5UFOVcABKAq4s3REJIraKLtCRJmNbRan7NRpJzCXw1oA+ZedikEAq5ahQAIVmWJQDt\nAGIATlEUZVn69acAXFyk8RFCahhdwAIS8MFLZHzwkjnGaymbamfVXjhFJxighU28U4hgDwCYCWAj\ngB8DuAeaVa3TD03ICSEkJ7roSpKE5sYQLlw8zXgtmbQT7HKNrLTUyv9ByovnNWwAtwF4WlGUf5Vl\neRqApQDCwuttALpzHWDMmGaEQsECPrry6Oho83sIJA3PReXg9lzoXasikVDWeyJN4ZzHGT26uWrP\neXNzQ1nHXq3fEzFTiGAfBRBPP+5KH2OVLMvnKYryAoDLADyb6wBdNjWCq5GOjjZ0dvb5PQwCnotK\nwsu5iMY0wY7Hk8Z7br9uMe769Ur09UWzjiO6yY92DaCzsTon/v392f9bqeBvo3IY6cSpEMH+PoAH\nZVleBqABwB0A3gRwvyzLDQDWA/jjiEZFCKkL9FKj4pqans5lu4aN2ljDruKhEx/xLNiKogwAuMbm\npfNHPBpCSF0hrmHrBNKPE6lU1v7mwinVK3vVGOFO/Ie5BYQQH9HTujJbguk62/mixKtYr+HQ7puQ\nnFCwCSG+kTLSujKKrac8JW0F2/5xNSBOQGhhk0KgYBNCfMMQLtHCdivYVWJi6/9jLJEUtvk1GlLN\nULAJIb5hu4atC7YlD1tV1aornHL3w6vxtZ+9AQCIJTJr8rSwSSEUEiVOCCFFQReugMnC1uyIpCXo\n7Ghv1NbqrmTWbTtqPI7HRcH2YzSk2qGFTQjxDV23JJs1bGvQ2c6DfabXq81KFV3iqSobO6kMKNiE\nEN/IuMQz2/Qocas1vbezHwBwzIRW03urhXiCFjYZGRRsQohvqDaFU/SIcatgd/fHAADjRjVq7y39\n8IoK17DJSKFgE0J8w6h0JpjYIQcLu2dAE+zRrREA1Sd68TijxMnIoGATQnzDziUecFjD7umPIhiQ\n0Nas9RqqNs0TLexU1Y2eVAIUbEKIb9gFnRku8aQ5Sry7P4ZRLQ2GoKtVFDGuqirXsMmIoWATQnzD\nLq1LkiQEAxKSFlXrGzQLdhXpNVTVGnRWRYMnFQMFmxDiGxndkkzbgwEpq3BKMqUiHAwY7vNqSo1K\nqaqpmQkFmxQCBZsQ4ht2FjagrWNb17BTKRWSlHGZV7pL/Nk39xiPUynVFERX4UMnFQoFmxDiGykj\n6Mys2KFgAPGk2SJVoYm1LtiVLnq//tsm43FKVdn8g4wYCjYhxD+MtC7z5kg4gK6+KIZjCXE3SFJm\n32oSvVTKXBu9ioZOKggKNiHEN+yafwBAQziI4VgSn/3BSwAy69WBgCQEnVWP6qVUs0u8miYbpHKg\nYBNCfCNlU+kMAMIh7daUSLvFM2vdkiHu1SfYTOsiI4OCTQjxDScLO2B5rmudJElGgJpqTtOuaNSU\neQ27miYbpHKgYBNCfEOF/Rq2Vc9SQjR5oAot7GTK6hL3cTCkaqFgE0J8Qxcuq0VtXeM1moRUtUuc\na9hkZFCwCSG+YVdLHMgWY13rtKAz83urgZQKWthkxFCwCSG+YVia+VziqYxLvBotbK5hk2JAwSaE\n+IaTS9wqaKJLvFoqnYmkVJV52GTEULAJIb6R6Ydt2W4tS2pyiVdHpTORVEo1NTPhGjYpBAo2IcR3\nJFiDzmB5LrjE09uqya2cUs3tQqtn5KSSoGATQnxDdbCwmyIh4/HPntxgWNySlLGwX1l3ADd+eykO\ndw+VZ7AjIMU1bFIEKNiEEN9wav5x01XzjMcvrt0v5GFn1rB3HOhDMqXi5bcPlGewIyA7rcvHwZCq\nhYJNCPENJwt78rgWHD+t3XieEfbsfauBvZ0D2Hmwz3j+9vajiCeSPo6IVCMUbEKIbziVJrVuGxiO\nAzAHnVUTDz65AfuPDJq2PfrSdp9GQ6oVCjYhxDf00qR2GixGUnf1RtP7SVVhYbuJAt95oC/vPoSI\nULAJIb6Ry8IWJa+rL5reLztnuxL1201QWTDA2y/xBq8YQohvGGvYOV4DgKFoAoA56KySSbnoJBYK\nVv7/QSoLCjYhxDecosQBmEzshJDWVQV67dLCroJ/hFQUFGxCiG84RYkD5kpmybTJGgggO+isAhXc\nzRp2MMjbL/EGrxhCiG/kXMMWRE+vwx0Q2mtWMm5c4rSwiVco2IQQ33Bqrym+BmRaU0rVsoZNlzgp\nARRsQohv5Aw6g2hhiy7xcoxsZLgSbLrEiUdC+XchhJDSoMuavUs88ziRElziFZnIlaG7P+pqhCFa\n2MQjFGxCiG+IXbiyX8s81tewxeYflcjKTZ344SNv4aJTpuXdN8i0LuIR+mQIIb6R6YdtVzhFcInr\nUeJStrhXkuy9tv4gAODFNfuyXjtnwWR84dpFxnMWTiFe4RVDSBkYHE7g4aVbjIpdJI3boLOkmIdd\nSRJtZjimNfRoCAezXlswazxOmDnWeM6gM+IVCjYhZeCvy7fj6dd24f7H3vZ7KBWF67QufQ27wpt/\nDMe0imyRcPattbHBLOJ0iROvULAJKQM9AzEAwFFa2CZSOUuTZh4nDJd4dqWzSjK4c1nYVsGuZE8B\nqUwKCjqTZfkOAFcCaADwIwDLAPwcQArAOgC3KIrCFu2EkJx4LZxi1/yjktAt7IZQtmBHLILtphoa\nISKeLWxZls8HcJaiKGcDOA/AMQC+B+BORVHOhTZZvrqYgySk2smVb1zP5CpNal7DzljYVsFOpSpH\n+HQL29YlHrYKdlmGRGqIQlzilwB4S5blRwE8BuBxAKcoirIs/fpTAC4u0vgIITWMrll2VnPKZg1b\nkrLFPVmBgh0O2Qh2xOzQpIVNvFKIS7wDmlV9BYDjoIm2+BPqB9Ce6wBjxjQjZOMyqkY6Otr8HgJJ\nU8nnIhIJAwBCoUBFj7NYuP0fW1sjAIBRoxqz3iMGl0npx6NGNWXt19TUUDHfaTyheQKCNve3aVPa\nERa2l3PclfL9kJFRiGAfBrBBUZQEgE2yLA8DmCq83gagO9cBuroGC/jYyqOjow2dnX1+D4Og8s9F\nNBoHACSSakWPsxh4ORe9vcMAgL7+4az36G5wABiOapbr4EAUR48OmPbrH4hW3Hc6OBzP2tZ1dACS\nJOGz712Ae/64tmzjrvTfRj0x0olTIS7xlwBcCgCyLE8B0AzgWVmWz0u/fhm0IDRCCMlJptJZtks8\n0pCxJ/TCKZJN4ZRKconriJMNHT2wrrVJ87bQI0684lmwFUV5AsAqWZZfB/BXADcD+DyAr8my/DI0\nq/2PRR0lIaQmSeWIEv/Uu05EU0RzIYvtNa152JUUdKaTSJrH9P4LZhuP9X+Va9jEKwWldSmK8iWb\nzeePbCiE1C5G+pK/w6hY7L6XqeNb8On3LMB3frsKh7qHAGjr2tbmH6s2d+KaC2dXRF6zBC2QLiFY\n2MdMaMWlZ0w3nuveBOo18QoLpxBSRipAUyqKVI60LsCmbriU3V6zs3sYKzcdLsHoCiA93oSNS9zY\nJb2PmxachIhQsAkpA7w125OrcIrddrs8bAA4VCGBrLr1L7rErbqs70O9Jl6hYBNCfCNX4RQAWevV\nTs0/Kq2RRq4mL1zDJoVCwSakHPDmbEs+C9tqTWvNP2z2qxDBtv83zOeea9ikUCjYhBDf0HteO+mt\nVQADkr24B4PVcysz1rC5UEI8Uj1XOSGk5shYme4sbMlhDbtSXOJuggolWtikQCjYhJSRSkg9qiQy\nhVPsX8+2sLUNV54903Z7NcA1bFIoFGxCygBvzfbkKpwC2AWdaX8XzB5nOU5lfMO2bUItzzNr2JUx\nZlI9ULAJKSPVYweWh7xR4pYXgkHteUtj2LTdrhSoH7g5v5k87JIOhdQgFGxCygFvzvbkzcM2P4+k\ne0o3N5qLNFpLgVYU1jxsWtikQCjYhJSBFGuT2mJUOnN43eoSb0i3p2y29JaulAYgboaRWcMu7VhI\n7UHBJqQMVGKDikogk4dt/7rV8m4Ia7esUDCAD18qG9tzlQItJ26sZq5hk0KhYBNSBpK8Odui52E7\nF04xP9dd4gDwDydNNh5XjoWdGce4URHbfZjWRQqFgk1IGUhW8hqrj+ii5ZSWZd0eDmVuWWLudSVY\n2KqqmkQ4lC7mYj3zbP5BCoWCTUgZoEvcHu8u8aDptS/988kAgHiiEgTb/DwUsr+90sImhULBJqQM\n6C5bCrcZNU8wnjXoLGwRwcYGLfjsmTd246DPHbusFnMoXfTculbNwimkUCjYhJQBCrY9+V3i1ufm\nDaFg5vm6bUeLOjavWAU4FMrt5qdeE69QsAkpA8lUKv2Xd2mRVJ7CKflKuYpNPxobgjn2LD0pi1c+\nZNdWDFzDJoVDwSakDOhCTcE2k/GIuws6sxISTHDdPe4XWS7xoP3Y9f+Vek28QsEmpAzoQVF0iZvJ\nV5o0X08P0cKOhP29nWULdm4Lm2vYxCsUbELKgC7YtLDN6N+G2+YfVoKCFev3V2vV36Z0NbawRbiN\nNeyyjIrUEv76kAipE2hh2+Ol+ccHL5mT9broEvd7Tdh6bt93wWwMRRN43wWzTdu5hk0KhYJNSBkw\nLGzepE1k8rDzN/+4cPG0rNdFl7jq82TIKsBj2iK49X0Ls/ZjHjYpFLrECSkDtLDt0S1sJ893Ppd4\nqIJc4m7PLdewSaFQsAkpMYlkyrC+KNhmUvks7DzvDwYCRk1xvwVQ//g509rx9Y+d7rgf87BJoVCw\nCSkxYtnMZEr1XVgqhYNHB7FszT4AzsKcLw8bAGZObgPgbk149ebD+MEf1pSk9rj++R2jmzC1o9Vx\nP1rYpFAo2ISUmLhFHBhspPGL/1OMxy502RHdYnXjvbjnT2uxZusRbNzZVfgHOmAUgcnjxtcnIXS2\nEK9QsAkpMfG4RbB5pwZgnsi4saSd0Ne5vUyESnEG9POar9gLoE1QaGETr1CwCSkxVgubudgaYlT3\nSCxsI03K54ZdRl30PBY2oIk69Zp4hWldhJQYa+tHWtga4teQyyr9/LWL0NoUdnzdcIn7nYedJ6dc\nhBY2KQRa2ISUGKtg3//YehzuHvJpNJWDW8GaN3Mspk9sc3xdt2h//tRGxBNJl5/tajdPeHOJS1zD\nJp6hYBNSYqwismbrETz45AafRlM5iKI5ojVs4b0vrt0/kiGNiHytQkVoYZNCoGATUmKsFjYADMXc\nWYK1jChYLpZ9HRHXjAeG4iMZ0ojQXeIOXTVNSFzDJgVAwSakxMRsBNup9WI9Ia45j8zCzjy2BviV\nk8watpugM1rYxDsUbEJKTO9gDIBZpENuzLAax+wSL/w4ogvazpvh8OmFf6DTEVPZ43FCAtewiXd4\n1yCkxPT0a4I9tq3R2BakhV00C1ssVOJWsEshlt5c4oDKBpvEIxRsQkpMz0BasEdFjG2hIH96qaJZ\n2JnHbgW7FJ29Mo1M3EWJ0yNOvMK7BiElpqc/CgAYI1rYI4myqhHENVwpb5sPZ0wucZdr2KUoXqOn\ndXENm5QKCjYhJaZnIIZgQMKolkzxD1rYFsEeSaWzglziJRBsI60r/77MwyaFwLsGISUmGkuisSGI\noLC4yShxc9CZGzeyE4UEnZXEwjbWsJmHTUoDBZuQIpJMpbBszT70C/nAiZSKYDBgupEHaWGbBavM\na9ilKA/rfQ2bgk28wbsGIUXkhdX78POnNuK+v6wztiWTKYSCEkIBMa2LFra5lnjhxxEnQm77XJdm\nDVv763YNmzXliVco2IQUkYNHtRrh2/b1GtuSKRXBgGQSFt6qi1k4xfv3WgrB1o/pxiUeCgaQSPIq\nIN4ouFuXLMsTALwJ4CIAKQA/T/9dB+AWRVF4NZK6Q8+tlSTgUNcgvvPb1ejqi2LyuGZTZDhbbBax\ncIookC6/1lK6xN1kAIRCASR8LKNKqpOCLGxZlsMAfgxgANrq090A7lQU5dz086uLNkJCqglDByQ8\n9douHOkdBoAsC5vuUGuUeHEsbLcToZJa2C7+lVAw4GsZVVKdFOoS/w6A/wWgt8ZZrCjKsvTjpwBc\nPNKBEVKN6DIgwSxC1qCzehDsVErFum1HEIvbNzopUsyZyTpPuhTBUnz/XqLEw8EAEonavwZIcfEs\n2LIsXw+gU1GUZ9KbJJh/b/0A2kc+NEKqkPQ9WJLMP4pQwFwapB5c4ktX7cXdD6/B757dbPt60Szs\nApYakqniW7de+mGHghJSqloXEzdSPApZw/4oAFWW5YsBLALwEIAO4fU2AN25DjBmTDNCoWABH115\ndHS0+T0EkqYSzkVjk1YcJRCQ0NSUKZTS2BhGqCHzcwuFgxUx3lLR0dGG3Z0DAABlT4/t/6pa9i+U\nYUF7VZfHampqKPr339JyFAAwenRT3mM3NzcAANrHNKOxoeBQItfU8rVWT3i+UhRFOU9/LMvyUgCf\nBPAdWZbPUxTlBQCXAXg21zG6uga9fmxF0tHRhs7OPr+HUdU88coORONJvOfcWSM6TqWci8EhrW64\nqgLDw5mgolQyhaPdmet+aCheEeMtBfq50L8LqKrt/ypawyP5LrqF7zUWT7o6Vm/fcNG//+5eLUOg\nvz+a99hq2nV/4GAvWhrDOfcdKZXy2yAjnzgVY2qnAvgcgPtlWW4AsB7AH4twXFIH/OmFbQAwYsGu\nGEzrskLedTCA4VhmLbceXOL6/xh0al9VpK9A9ED7m4ftIUo8XTgn4bodKCEjFGxFUS4Qnp4/sqEQ\nUv0YQWeWe3YwICEqCHaqBGuolYaeZ1zqVqKFRImXJOjMwxp2OKQJ9q5D/TixpWFEa/ikfmDhFEKK\niUNDi1BQwvjRTcbzerCw9UlJqau6iQLpthhJKS1st4VTAOD7D6/BC2v2FX0spDahYBNSRMS0LjEs\nPBgM4NLTj8H1l80FUB9pXUkPLuKRYI4Sd/ZciJXVSpPWlT0eJ8JCLfm3tx0t+lhIbULBJqSIqIJP\n3LSGHZAQDgVx7sIpCAYkJOug8UPGJV7a20zAlIft/L2KIl2K71+fLLhK6wpl9mkI10bGDCk9FGxC\nikqmNKlksbCNxwGJFnYRkSx52E5dsMTvvJQWtpegMwBobKBgE3dQsElFUCutBvV/w3rLFgOvAgGp\nLtawdYvTScCKdc6tFq3Tdytuz2WJF0om6Cz/vqJLPEILm7iEgk0qghrRayFKXDIJSShgtrDrQ7Bz\nu8RTpRJsBzEWP6+klc5cNv/QaQjzNkzcwSuFVAS1ImCq+H+YXOJmC7suXOLJ3C7xYmmmNc074XBg\n8RorRWtLL7XEQ5YlEkLcQMEmvlHqqN1yo+zqwvJ1BwDY1BIXBLt+LOy0S9whD7tYFnbW5zqI8Z5D\n/cZjtwVWvODFwg4HzevuhLiBgk18wxS1WwM3rf/6zSrjcdYadoBBZyLFFOtwyHwbcxLjV9cfNB6X\norVlpr1mfsHuqLOcfFIcKNjEN0xRu7WyiG0gmf6nkMUlHquDkpSi29kaYFbMCUswEMC9t52Ls+ZP\nBOAsgOIYSlES1Etp0hOPG4db3n2iNhb2xSYuoWAT30iWOM3GTyTJ/P+JFrYkSegdiEHZ1eXH0MqG\nfk6Xv3UAd/zkVdvXikVTJIRwugOgkwCKcwa/17ABYMKYZgCliVgntQkFm/iGOWq39m5aoihFhFzb\nSWO1G/XewwNlH1M5icYztdMPdQ2ZXiuFR0X3YjhdS+JnlsIl7qWWOJCxxBM1eO2T0kDBJr5RyxZ2\nMqXipbWOgZlkAAAgAElEQVT7jectjZk+O/9w0mRjn1ombnE7v7R2P4aiCQClOd+6F+OFVftsc7xT\npijxEgi26q1QjDHBoEucuISCTXxDdAXWWqnOrr6oaZ26OZIRbP2GrtawYNsJ5oNPbsBv/rYJQKYq\nWDEZ1aL1lX525R7s6cz2XuifKUmlWcPWJ2CSS8HWJxilcM+T2oSCTXxDtHhqWbwAoLkxbDzWb+i1\nNkkREXt/i2zb3wsgc+6Pn9aO7396SVE+852nT8esKaPSn5/Iel2/xhrCwRKldWl/gy5d4hkXPi1s\n4g4KNvGNZI2vYYs0N2Zb2LW2DCAyOJwtmEAm8Es/32PaImhvjRTlM0PBAOYfO1Y7vo3VagSFScCR\n3iiWv7U/a5+R4DXoTK8Ax6Az4hYKNvGNUjdjKCf56mKLgq0HJVX7/5yLwaiTYKumv27FzS26CNpV\nO9O/76GoZv3/9IkNRf1sL4VTACHojGvYxCUUbOIbpmYMVSBePQMxbE+7dAFNdDbu7MJwLJF3/OIa\ntn5D7+wexqHuIae3VDWDw3Hb7aqqfW8bdmopbW4jqt2SCeRSsedQP/oGY8Zrpb7EvDT/APJHtRNi\nhYJNfKPaCqd84UfL8fWHVhiRzmu3HsG3f7sK9/3l7bxWklg7Wr+hv/TWftx+3yslG6+fOLnEU6qK\nJ17ZaVi3Rbew04Fc3f1RfPXB1/HvP3vD9NmlxGs70UzQGS1s4g4KNvGNaitNqkfz6jfYPZ1abeq1\nW4/kjPT9wgdONj0PWrtV1CDDcfugM1UFVmw8ZDwvlYV98KjmuejqixqvlXoJQp8QSC7/p0BAyiqw\nQ0guav/OQSoWcZ2xmtZz7W6w1pxjkePSkcs6krW7VI1ZWP2DMdz/2Hrb11Kqir6hjLu8+Ba2dryn\nX9+V9Vqpe657KU2qEwoGmNZFXEPBJr5RrUFndlG9uUTXakVab+hO7uNq5ddPb3R8TVVV9A1mBNtt\nCpRbQg69t4HyWdheJiFa57bamrCR0kHBJr5hcolXwRq2jl0Eci7Btgq0VcCdIqqrlV4h0MuKqpq/\nK6u3YaTksm5TauEu+EPdQzmF9WDXoGEpexHsUDDAtC7iGgo28Y1qKk0qiozdDTaXS9yqEdYb+oBD\nRHW1kuu7sLqli7+G7XxLU1UVkgQ0puu6u/3orft6cPt9r+BBhzSwNVsO444fv4pNu7shwdv/FAxK\nJalrTmoTCjbxjWoKOhPd1nbWdK51SGsQUq27xGMOAWdAdmqVl/VeN1iPd8yEVuGzVQQCEv79htMB\nANM6WuGGrXt6AACvvH3Q9nVld7fx2OuafFNDCMM15mEhpYOCTXxDFOlfPL3RFNFbbrbs6cHDS7c4\nBiaJVrDd5MJL4FiWS7zGBDuaQ7CzLOwSFU4BgHAogN2H+vHbv29GKqUildK++wmjm9DaFHY9Scy3\nW0NISNnz+P80N4bQOxjHa+vtJwOEiFCwiW+IFnZ3fwy/ekbxbSz/+as38fRru4xa11ZEEbJziTuJ\nlJ0Fab2pD9nUva5m+gedXfzW+ZDbFCi3BIOZ4+mu77+t2I01Ww6nLezMfm4nWfnyt8OCYHv1GOgV\n8H7817dLHsVOqh8KNvENq4VjDVaKJ1JlT3ly6uIkurztgo+crOT7Pn9e1jarhV2KzlF+0j+UQ7Bh\nPufFdomHhOM1hDI9yPuH40ilVOO7DwUCtm0to7FklnDmi68QP6chHMyxp914M7dgPz1MpDqgYBPf\nsAq21dr6xHefx+fuXV7OITlafOLN3W69WizFOXV8i/HYrkiK1cKutTzcgRyCbf1fi6zXJpd4SLC2\nf/bkRuw9PGCc32BQQsJy/R3uGcKn7n4Bv3xmk2l7Pss3HM58puged4MYcLbrYL+n95L6g4JNfMMa\nTWx3MfblcK+Wk0Qq28IW7+N6ataMSW249b0L8PlrF+GmK+fZHssq2LUUJZxMpYzSrZ+8en7W61nn\nvNgWtiDSdhHj+ufZpVNt3asthzy/aq9pe7417LDwORGPFrb4fdRatgApPhRs4huxhHnddyiWxBOv\n7HBsHFEslq7ai10H+wAA+w4P4G9v7DZec0rJyWdhD6Rd4h+8ZA7Gj27CvJljceb8SbbHsrqBa8kl\nrnfCWjynA6efMDHv/sVO6xI9GrbxA1LmNevShpMlrW93Gqm4xt0Q9mhhC+c+VzocIQAQyr8LIaUh\nFjffoHYf6sfuQ/043DOMj1w6tySfeaRnGL/8Py247cHbL8RXfvqaORDK4a6cNK1h6zWjM6/rkwyx\nK5cTVh2ppdKkupUothPNRSkt7GBOC1vKmng5eb7z1QgX17jF9Ww3XHTKVDzwuGbZxyjYJA+0sIlv\nOOXrHukdLlnErFUcs6KWnd4n3JTtBFYPOmtpDOcdQy27xPXvwc3EBSiBhS2ItBgxbv28YMDsEldV\n1TEaXDfEnXq2iC5zr0FnZ584GTddpS2dxBPO6XCEALSwiY9EHW5QoUCgZIVUpHwWnaOFnRHV+x9b\nn1XsQneJN7kQqiyXeA0FnWUmLj5Z2MLxQrYu8YyFnUqL9OBwArfe8yKmCMGCOl19UTz56k4ALi1s\njy5xABjTGgGQ7XEixAotbOIbTjeokIccWa/kS9FxsvisomqNJO4bjKEpEjTl5DphvfHX0hq2nprX\n1twAAPjoZXOxcNY4x/1L1a0LsHeJ6xM2fb9kUsX6HUehqsDezoGs/dduPZwZqwvBLuS/Cafd6FzD\nJvmgYBPfcHKJl7LloF3urYiTJz5fR6Xu/hjaWyKuxpCd1lU7N+qefk2w21s1wT5n4RTc+r6FjvsX\nO61LDCywt7C1v7qYP/PGLhw4Muh4uEhDxsXt5BIXvUFDMe9ubT0VrG8whudW7sHOA3153/P29qPY\nfyR7gkFqG7rEiW84BdkEg1JeYS2UfK52p7VzuwmEuGv/UBzTOrJdqnZYLbVasqy6+7XiH4VOXkZK\nY3oNua05bGth65MjXRT/9MK2PMfL3CIlB/tZvGaGCqgLrudxL193AMvXHUBrUxj33HqO4/6plIrv\n/X41AC1wktQPFGziG04WdjgYKFkgVn7Bdv8+q7i3t7oTKSu1FHTWM6BZ2KPTFnY+vOYt5z1eQxDf\nvPEMtLc04Bf/l13qVp8k6uPMhxi45jS5MFnYBQi2NbI8V6U46+eR+oKCTXzDSbCDJewRbD2ulo8r\ntPl0UGw7i99632xvcSdSVhLJFH79t02QJOCfL55T0DEqhZ60hT3K5XfhNQ3KDZPHaZ4Ouzxsr4Fd\n4vXiFNA+0q5zbuIenD6P1Bdcwya+EU2kIEnAFWfPzHqtVOu64lq0qqpZUb2OLnHLTTIgSVk3zrbm\n/CldtsdOpPDsm3vw9xV7Cnp/JTEwnEBTJJRVZexd5xxru38hUdVuEV3irU3audGXHz56ubs8f/F6\ncQw6S18zoaCEm991oudxei1nSgu7fqFgE9+IxZNoCAfxnnOPM4KUAM2aLVXQWcJiDYUtFp6d9dI3\nGMO2vT2mbcF0WpBIs4scbDviNZTWNRxL2Ka2XbXkWJw6d0LWdq95y14ICRHh5yyYDCAzETxVzh6L\nHaI4OlnY+j6fv/ZkTJ/Y5nmcdhZ2Iqk1vtm6ryfrtXwBkKR2oWAT34gnUoikb1ZiPeZEUkVCuCnl\na2/oBdHFGYsns6wbu1vhVx54DWu2HjFtCwSyLWy3ucciWkR87dyAo7GkYy66XdS2V+vSC7qVn1LV\nrImB2y5h4vXitIatX5+Fdh6TJClLtKPxJP6wdCu++Ys38cq6A+bPo4Vdt1CwiW/oFjaQ6V0MaNaF\neKMs5g1KtE6i8VSW69bOJd5r04AkKNlY2C6re4k0NgQRLSAVqFIZjiXRFLG3mu0ErdhBZyJt6XV0\nVc12vdtVQbNDnDg6CbJ+fY4k4t06cRmOJrF6SycAYI2QCw7QJV7PeL7DyLIcBvAggBkAIgC+AWAD\ngJ9DM1DWAbhFURReVSQn0XjKCE6KWARbjJxOpVRAuK/vOdSPR1/ajo9cKhsFOtxisrATSVPtae2z\nMmN44PH1OG/hFNvjDEYT2LTb7K4sxCXeEA6YujSpqupYUavSSaVUxBIpNEXsvwc7QSulS1wMAgxb\nJmb5SqJ+/aE3cKQ3ivkzxxrbdKF85e0D2Ns5gPeePwuAULp0BOfNamEPx5Pp62nY6ASnQwu7finE\nwr4OQKeiKOcCuBTAvQC+B+DO9DYJwNXFGyKpVWKJjEva6hIXo7Ktluz/PLIWKzd14vGXd3r+TNE6\nGY4ms/pV6xb2mi2H8fqGQ/jO71Y7Hmv7/l7T80Jc4m1NDUZZU+v4qo1oOuq/0cnCtsmLLmXQmR5o\nBgAhiyDmmxRt39+H3oEYXnk7447Wz839j63Hk6/uNLIcimNhm7+z4VjCuJ4Gh82CnSxRnX1S+RTy\na/kDgK8K748DWKwoyrL0tqcAXFyEsZEaRlVVxOIpWwurs2fIFHRmjbHRXciFNEsQXeJ7D/dn5UDr\n98LhAtzUTQUI9vSJrabnnd1Dno9RbmLxpJG+JaJ/Z05r2HYu5VKkdemIE6iQU5kyDySTKoZjGfHU\nLV99QjkSwQ5bJi7RWNLw2AwM08ImGp6vYkVRBhRF6ZdluQ2aeH/Zcpx+AO1FGh+pUfT0Grugo72d\nA1j+1n7jeVbQWdo6KuS2JbrEH3h8A/YdNpd31D+rkGImhaxhW6OK//X+1/D6hoOej1NO7vjJq7jt\nh8uzopV1MfMi2NYliWIydlRj5nNCI/+cVErFXuF60YVUt7xHUrQtaw07ljQCMocs/eGr2QtDRkZB\nhVNkWT4GwCMA7lUU5beyLH9beLkNQHeu948Z04xQCWfW5aSjw3saBwF605Wm2loj6OhoQ0OD+VJc\ntTkTaDNmTAtGt2WqiOk3+UgkbPr+3ZyL5jwlM9vaGtHR0YbGRvu18W988mx8+b6Xs7bPmT4akye5\nn6f+56eWIJ5I2abobNjVg388d7brY5Wbrj7Nuh49pgWNwnnrFjqW2Z2LNptKcBMmjCrRKLXr4c7r\nT8cxE1uxS6jPXehvNqWqCDVk3OyRxgZ0dLQhkp6gdIxvQ4dNxy83NDeZr7dgOIRg+h6ZVM1j7otl\nrhm3/wvvU7VBIUFnEwE8A+BmRVGWpjevkmX5PEVRXgBwGYBncx2jq8u52H410dHRhs7O/IX6R8Ky\nNfvw8roDOG/RFJw1f1JJP6vUDA7H8eiL2/HO06cbOa1qKoXOzj7EYs4lHTsP9yE+nCklqRvcg0Mx\n4/t3cy5UVcXvnskuVynS0zOEzs4+dPXYX6NtDfZOqdPkCZ6uhUntmnjZNXp4YdUeXHraNDy/ei+u\nWnKsq5adftDZ2WcIdjSWxHd+uQIA0NgQsv0uojZlO0v9+5k9SVtyGBrMuPAL/czhWBJrNx0ynn/x\nhy/i/RfMxkC6Q1l31wBCamEpepLFi3TwcD/6BrQxDwzF8T+/W4l/Ou84hENBHD7Sb+zn5n8px32K\nuGOkE6dC7gR3QnN5f1WWZX0t+1YA98iy3ABgPYA/jmhUxODnT20EAGza3V31gv3X5Tvw9zf3YPuB\nXtxw+QkAnNcwJSkjzNY1O0PsPQbf7OkcwJHe4Zz76C5xu5aX7a0NjuIppqV5od2h5vYdP3kVgGbN\nfvJq79WzyoF4Xjbv6cb+dNermVPsrWYxD7u1KVxSd3jWZ9sEvBXCn5eZm4U8vHQLTksXhBnRGrbF\nJT44HDc1hXnmjd0YN6oR7zjtGJNLvJqzCoh3PAu2oii3QhNoK+ePeDSkpulL5zN398XQnXarOkUJ\ni1qcJdh616Qceh1PJI2btH5D23u43/kN+melP1hvEiFBy9mdNLYFX/nIqY43/kIFe1SetLSNu3Ku\nLvmKeFp0cblqyUwsWTDF1qITc5+/e/PZRRNRN5Tys/S0vBFFiVuCLweHE1nd7HShFvP2U6qKIAW7\nbqhMXxsBkG1BplR1RLmefqMP/UjvsJEupRfOGNPW6PS2rKAz/ThOsTd/fWk7Hn1pO04/YQJe33AI\n//XJs9Axugl7O/P3D1ZTWinSJ17RUsaCQQmJpIrWplDOJg2RAgU7302+12VXKT8QLT295GuuvHgx\nhS4cCpTVMmwuIILfLf2DIxds67X17Jt7suajw7EEnn5tFx5eusXYlkyqKOO8h/gMT3UFY62nPRyt\nnYpYOnru7rUXzcalp0/HxadOy9rHGhVruMQdTOxHX9oOAHh9g7beuHFXF4DsfFY7UqpquHZFrHm8\nVsS+yV656cp5Bb/XT0TPh15eNZebW4wSL7cbd+r4Frz7nGPxrx86paD3v9uheQkA9KXbYRZamhTI\n9gDYXdk9AzE8smyraRsjxusLCnYFY80zHhzO3Se3GjlwVBPHtuYGvP/C2bjktGOy9rHek/Sbvdsl\n7JZ0PqubVK29nQN4fvVe47k+abJWyrJSqEscAM6cPwmXnjHd8fVKzbsVI9wzgu38PbktB1oKJEnC\nlUuOxayphWWcLpw93vR8qhANrvevHon3K5oOuhw7KuLYZKSnP5ZVypWCXV/QJV7BRC29e60lCmuB\nM+dNND23K6SiZlnYumC7u1nplo9dT2srT7++y3Z7vp7FhbrEdQaGnCdjvYMxjLZJifIbs4WdboDh\n0sKuNiLhIELp5RHAXJRFX78fiUtc9/60NIaRSKRs69f3DsbQEA6aK+PVUOMYkh9a2BVMzGJhWyse\nVTsfv+KErMj3iE3UeNYadvqvWwtbt/5G0rIzX0WukVjYQO5z29NfmevY4jzKsLBzVBTrzzEpqXSC\nAcmUc97SlF0vfSQWtj4Zb4qEcMyEVtt9orHs7nK0sOsLWtgVTMxqYdeYS3x8e1PWWqa1RCMA/PvP\n3kBTJIjLz5yBR1/cbtyk3N6q7v3zOly1ZCbe2Hgo/84O5FvDHmkTi1zGWXd/FDPgT+GLPyzdguVv\n7cd3b1mS5e4WxUKvIJfrexoY0kRpSoHFRfwkGAyYYiBabQS7GGvYY0dFMKY1grd3dGXto9UXN39u\ngoJdV1CwKxi9uUDmeW25v+xSukQrJSC0sByKJvGnF8w5sF7ysP+6fIfx+FS5AyuUTk9jbRIs6Jvf\ndSLWbT+CgaEEtu7rwZnzJo24TeR175iDHQf6cLgnO0+8x8dI8ade05YIuvuiGD+6yfSa16Czy86c\nju6BKN573qwSjHTkXHLaMZCnj8a6bUexdNVe02vBQOZanDK+xTYffyRxdB/7xxPwpxe24QMXH4/1\nO44a26/+h2NxuHsIG3d1YziWyMqmoEu8vqBgVzBWwS6kvnUlk8/NfOkZ0/Hkq84duXS9VnZ1YTgF\n7NnXk3etGQA+cfV8rPj2816GakoLOnXuBJyaLpZRLNpbI/jEVfPxzV++mfVat9BoY9PubhzqGsLx\n09oxcWxzUcfgFVvBzuESb2tuwE1Xzi/5uArl2ouOBwCcfHxHtmALE5GPXjYXKzebJ3wBSRpR5PvY\nUY24MZ0tINaXv/oftOj0b/5iBbbuG8aWveaWrlaX+Kbd3Rg3qhGhUABb9vTgFLkDKzYcRFtDwFRb\nnVQnFOwKJmopnJCoNcHO01ox3/+rqipUVcV//WaVp88NSBJmTR2FrXt78++cppBe115xCloSLey7\nfr3SePzg7ReWfEw6dq7XpE3QWTmLoZSTcDCACaObcKh7CNM6WrF6y2HT68WMgJ8wRvNkiOvVThNR\nsZlN32AMd/16JYIBCRPGNGH/kUHceMU83P/4ejSEA7jvc+cXbYzEHyjYFYzVwrYrl1nNOK37fu+W\nJZAksxvbDlUtLJBMkiR87ppF+OL/vuI6EKqQXtdecVoD1YPOrGl+8UTKlUehGMRtrj07C9vP1K1S\nce2Fs9EQDuLLHzkVg9GEbUZAMeu9ByQJ3/7UWQgLHign75o4adIndslUppbAln2aRV5ry2n1Sm1O\nh2sE64+s1lzidhHhADCmLYLRrRHE47kLxWzf34uvP7SioM9ubAhh5iT3gVyFtM70ipOFvXJTJ37w\nhzX48gOvmbbvPdyPLXt78O3frDTKY5aK7/1+NfqH4viPn79hbNPXdPsGY3jmjd0A8uerVyNTO7So\n7damMCZY1vF1ij2hG9/ehPaWTNU4p/7s3/zFCmPSaVcVL+5BqIdjCXzrV29meQ9I5VB7v64awirQ\nI0lLqkTsIsJFrLWUrfQMxLCnM399cCd0gZzWkT9quSwucZs1UN3qXrP1CDq7zQFp3f0x/Ocv38TG\nXd1YtnpfScfWOxDD6s2HsUPoLqZbd0+9msldryYL+xNXzYd8zGjMOWY0bnm3ucHK9ZfNNR7nW7oB\nSj+hizoItgpgb/o3YJf+Z00NzcWKjZ3YvKcH9/xxbUFjJKWHgl3BWCNAC1nD3nOoH28qh3C0dxi7\nD2k/7OFYAtv3u1+/1dm+vxfDOdpgeiVf3qqdG7aY6J8vSRJue//CnPu6uWmPFDuXeK787i17MgFI\nIy3c4gZrp7M3NhzE3s5+KLszKUjVtIZ9xryJ+NJ1i3H7dYtximwOIjx34RTjcb7gSKD0Ezo7C3tG\nOjgtnkwhGk9ilY1l7GSZ2yGW+t1zqPCJMCkdXMOuYKwRoF4FLJ5I4Ru/WGGyVL/ykVPx8HNboOzu\nxr9dfxpmuHQL7zzQh68/tALHT2vHHR8srB6zV7xYB4WgpyBF48mslJz21gaTxWKXd1ts7FziwRwC\nKEbQl6Nn9iFLH/vnV+/D8xbLvpoE2y2uLOwSxzjMmznGqI2vk2kFq+LeR97Cuu1Hs97nZalEzJL8\n6oOv497bzq3YXuz1Su39umoIXbCPnaz1F/ZqYff0R7PcygePDkLZrbVs7Owecn2s/Ue0Tleb9/Tk\n2dMZ8Ybw7nOPy7t/Ppf4SNHTog51DWWl5HzthtONx++/YHZZSoPaWdhue0aXo974gaP5r5dqcom7\nJdekSafUgv3Ry07IqrOv3x8SyZStWANA30DhsQ3RPDEkpPxQsCuEo73D+NGf38IhQUT1H+SSk7Ty\nnc+t3GvKyc2HXcENcca8bX8vfvbkBlcTgUJzTPuH4vjRo+uwp7Pf1CxitosmDF4CZgphWkemBKTV\nPS/2qZ5zzOiSjsMYg41guy13+cfntxZUyW3t1iP49m9WYt32I8a2ZCqFB5/YgK9YgtzcLKPUYtBZ\nyEUFs1KvYUcagjjNkvuv/26tudki3QPm+8W67Ufw08fX207wrCWAay0rpRaovV9XlfK757ZghdKJ\nh57aaGzT17DFKlqPvrgt671OdNsEoYg/yadf24UX1+7H2q1HsvazUmhNiMeW78CKjYfwoz+vM7n4\n3bgZ33/h7MI+FFouq/UGZ2XBrHGYMr4FH3qnnLM0aI5aIEUlnzjnSuHqGYjhfx9d5/kz//ziNmzc\n1Y0XVmVc229tPYqX3tqPvYfz9w+34tYjUA1cfuYMjB0VQXurc49vQLuWj59W+kmdmAYZaQji7BO1\nibweoW+HNdPk7t+vwfJ1B+wnXxYNt9aBIP7DBQqfGY4lkEqpGE4X/4/GkxiKJiBJGQtbbDoQT9i7\nPgeH4wgGA4a4p1QVOw9m/yjt1sEPdeV3dRZqYev1z/uH4ugXOhA5pXSJnDBjDKaMb8G+AoTjrk+c\nhb7BWE6rsykSwjc+fgYArUKUEyNp6uCFfN2eTjpuHDbs7MJQkbq29fRHjQjjaDpeoHcwNqICPcFy\nzW7KwHvPn4X3np+7jGowIJWtIIk4yf3ffzkPr60/aLvfsZNH2QqyeF71a61vMIamSAihYCCr1K+1\nDgTxHwq2z9xy9zKo0IJKAK0T1S3fX4aWxhDOSUeqipHC4VD2TT2VUvHp/34R0ye04t/Ta6+//tsm\nLF2plVecMbENOw9q6TjW4hsAjOjxXBQqWXpqWv9Q3Fg7B9xHXU/1INgtjSFT1ysvAVCiKFvXkssV\neJOveYSb9o2qqrqaXPUMxHDbD5cbz4eGEzhwdBB3/uTVnAF24VAgZ/DjSFpMVhN6mc/pE+07a5UC\na7S60/U9blQE2/dnb/+fP71len6oewi33/cKzpo/CTdeOS+rmQ4Fu/KonelwlaL/SPTJrZ6GMTCc\nMMoOiik7dgEwB9PRu7sO9RvrULpYA8A/njUD49u1G4zdzdaNxVaokZl0yB13293qQ++Uce2Fsx0L\nVoi0Nptdl02REG68Yh6muugOJf5/X09b3f/xsdPx0cvnosPFZxeDfGLnphuU2xash3vMXpWB4QRW\npetj56r+1tZsL+bXvWMOPvWuE21fq0XOWTAZ1150PD7zTwvK9pkRyyTXbvIOAOPa7WuGv7Uts/QV\nT6SwOT2BfuXtAwCy29WWOuiTeIeCXSHo7ihx3fBvK7S1KXENWw/qWf7Wfjy3cg9+/9xmk+W6dOVe\nHDxqTr+ZMKYJ16TXg4ei2bPmzXu68acXtpqCTrbv78VTr+40xuXUGEvZ1YXnVu4xnr+9/SieX52Z\nLDhVZ3OT2wpo6VSXnD7d1YSh1SZS96wTJ+F4F0FjolU6KR09Pq2jFecsmOL0lqKT18J28SXYBSU+\n/vIOKLvM7RqtTToOHB3EH5ZuzXv8tib79dx5M8fkjRmoJULBAC457ZiyZA/oWCe5zhZ2/iYff3lp\nOzbvcV4GAspnYR/tHcbvnt1sah/83Mo9xgSSZKBLvELI5WYUA3n0e/ZPn9hgu++r6w/g6dd2mbaF\nQwEjYKl3MDsQbWA4gSde2Ym5M8Zg/syxAGCU/Dx+2mjMntbuuK6pN95YNHs8xo5qxPd+vxoAsOTE\nSQiHgo7v81qI5D3nzcoKqgoFJVP1N714xQkzxpj2axRudKfIHbbHr4SlVztBvmrJsXjwSe1cX7h4\nat6ykT39MUwT/sXDPUN4ZJkWqFiMZiGtDhb2SNuLkvzoE7o507QMCyfBdtOVa8POLmywNMKzRomX\nq/74T5/YgA07u5BKqfjnd8wBAPzqmU0AytvgphqgYPuIGOSRqyKR6AaPJ1K269A60VgqqyJVMBgw\nLGr1xTwAABYpSURBVPM+G8HWGbBxhe4/OoBZU0dlFXGxBqjs6exHi7D22d0fQ2tT2PH/cuPeFTlt\n7gScdvuF6OqL4nP3amuvP/78+ZAkCV9+4DXsOzyAcCiAn3zh/Kxji5ODmx3ctlLBq/TFw86A/ocF\nk3HGvInGhMu6y12fPAu33/eK8Vy3sBPJFIIBCYMOLnIvdelvuPwEY9Lg5BIXAyNJaZAkyXR9O2UN\neC3yox/P6kWLCvcZVVWRTKmOk4REMlVw0ZyuPu2a1dNQvfS5rzf4K/MRUQRzCbaYBxqLpxxvwgBs\na2uHApLR+UeM1LZiZ+X/7MmNOHB00LSGfMNdzwGAKYJ258F+PCesm39JEBE7Co06b4pkLDn9GHr6\nWygo2d40RFfiSHoWlxqnseVK54pYXvvpExswe2o77vjJq1g0ezwuO3O67fuccmyDASlrcjZzcqYa\nnpNLPNJQAS6KOkC8vp1y3ke15E5Ds6IXfRHrJADaveaHj7yFlZs6MW/mGKzf0YUHvnRBlido855u\nfOtXK/HhS2Wcv2iqp88GMrEbKVXF/7vnxaxlBlVV8fFvL8WJx47LW0K41qFg+4i4RpSrqlAwIOHd\n5xyLP7+4HbFE0nVgkU4omHGJ9+UIKNIF2zrDferVXfjgJXOy9v/j85k1z97+GHYKjSHsCIcCmD9z\nLBbMGud67HbHsJIwBNv+BtbgogWlVaT85vrL5uasIw4An/2nBbbfx2sbtHSf1VsO44LF9jdQcami\nKRIyAg8bG4LG9fUv71+IvYcHMHV8C770zydj16H+rInl569dhM7uoZpK56oWQg7X9aSxzbj2ouMx\nFE3gLy9tz3scvUiQNUA0Fk9i5SZtHXn9Di0GIhpLZmVNLH9LC1p79MXthQl2Wv9TKRW9g3H0WoyK\nWDwFVTUHzdUr/JX5SFRYI8oVmRsMBnDxqVpZwlg85bmiVSgoGTf2bfucq1XpUaGipayTyyIDtEhT\nu8pqImecMBGffe8CnH+y9x915vPsBFu70TgV7XATkW5dv/ObcxdOweknTHR8/eJTpmHR8ePtrW/h\nXxG9MWu3HsHSlXugqqrJmzJ2VMaiEb+reTPH4p2nT4ckSZCnj8E7Tj0ma7lh3syxOK+AmzQZObmK\n1Fxy2jE48bixro4TjSfx9xW78cJq8+/erpb/cCyJ51fvNZbWtu/vxdvb7YV0w84urN16GEPRBJ55\nY7ejZ1C32J1+gqVuHVtN0ML2EbfNLYKBjOBG40nHWbOdOxNIr2G7sDKHownsPzKAX/9tU9ZrR/vs\nS6LqnzeYttAWzhqHNQ6V04rZUUpcl9atRaeaz24C3MpRi7sYXLB4Kp54ZadxM7bzKhwWYhjEyNv/\n/sMaAMDkcS2mNez2lgbs7dSyE3RvREM4YJtmJk8vT5lWkp98ZWAnjml2dZzDPcP4zd83Z223a9f5\n1Gs78fcVe/DGhkP4wgdONvWjt14t3/mtFpB60eJpeHblHuzp7McNl5+QdUx9KcgpQHWwSIWCagFa\n2D7iNgozGNDWZoMBKacV6+QSDgcDrtzCA8MJxzG5ra71rnMyTT1uuPwEfPX6U43n+Vy8brnn1nPw\ng8+cYzxPpMXWmqqk4yaFrFoCXd5z7nH47s1nY8Gs8QDM6956c4gjPRnBtls+6R+Km26OYmtI3cJ2\nCiKbNaU9qwkF8QfRJf7Z92bng7c2hXHPrefgD9/6R1N/b7fobnARvfmPXTEjp1/QvnTjoAOWdFMd\n/WfrlEaWK2an3qhrwX5+9V589gcv5nRHe+VIzzBu+f4yvL7BvmxgZ/cQbvufl7Bhx1HXeY56B6SG\ncDBnGVGnyOuAYKHnYnA47riWPuSir+64UY1oaQoJzyOmBhvFEuzWprDJWtfTtsSANJFy9LIuF5Ik\nOabt6ME6YlEUJ+tETIdraxIFW/uuGnMsI+iFObxG+pPiIk5Qx7bZ54O3NoXR2BDC5HHurG0Ra7YJ\nACNOpbkxlOWV6h2I4Ya7nsOm3d34yWNvG9v1/ezSFjfs7ML2/dox7Qq1vLXtCO769UrjebVMrEtF\n7dzJCuAXTyvoH4pjXRGDGZat2YehaAL3/eVt29effm0XegZi+NGj61xXEtIv9JbGUM46z6rjHFcL\nLBpt08RA/A31DcUdo9WHXVjYLY0hNEcyN//GSMh0Uy9Vru7/e99CLFkwBZecZh8R7cbCPn7aaJx9\n4iT8yzX+RqG+59zjcO1Fx3t6z9duOB1nzp+ICxZPRSgYwOEee5e4jopMgGEoGDDlrevfVa4J3jkL\nJuPUuRNw54fK0xed2BNpCOKiU6bhpqvm5U2pmjW1HRctnob3CZkdFy2ehrkOSxxjHCYAOi2NYdua\nDgDw/YfX4NW3MwZLIh19bje/E5ff7FIN733EXE41V72KeqCuBVtHX/tct/0IXlyzz8gLLIS4ELG8\nZsthRGNJrN582LCm9QjLgeGEY6Uh60RUd3uKXYPOXTg5632pHNeyJEm2brGWRjF3OorhmCbM173D\nHBVuFXK7z29uDKFRsHIj4aDJZVuqXN0Zk9pw+0dOc+xJ7MbCDgQkfPyKeTjx2MIj2IvBFWfP9Oxy\nPmZCK266cj4i4SDaWxpMwTsrNmZXi1q37QheTZej/NTV802uVX3pJFf6W2NDCDe/60SjTzvxj+ve\nMQdnzpuUt0taQJJw3SVzMFeYnF13yRzH3+SlZ9hPfnVaGkO2a9xAdsbL1r1aoKuqAm8qh/Cm0ilY\n3Zn99DgKEatRM1zn9c0ZdAbtYj7SM4y7f68F5TRHQvjhbecWdCx9BphIpvCDP67FtI5W7Onsx6LZ\n4/HZ9y4wuW0ffdE+eOy0uRPw+obsSPDRLZlZr11AST53kbhWqdPWHDaWBHr6Y4imhbmxIYjJ45qx\n/4i27mRdw7arry1JksntZXWBF8sl7pVa7NHsxOjWBpMr084l/uLaTGeIUChgnMvjpowyAs2sObmk\nsnFbtERf/tCXqpyWkZwK5Og0RUJ5s0KsKLu7jTLK7z73OFx59kzPdRGGY0mM8u7drxnq506Wg0DA\nnDowkqhEq8tGL2Sil5S0S0u6/brF+O7NZxvPr1xyLG6/bnHWfqKFfdyUbOsmX6Bzs03XqVFCw4ze\nwZjxv0fCQfzrh07BkpO0nrtDMfN3MsFmwmBd86oUwXaKHq9FvBbNCAUDmDS2GV//2On43DWLjPVp\nNy1XSeXgtkva+NFN+PrHTscdH9TuL9c4LL+Eg7l/q4mUarvc4pZte7XgNa91jKIuYmlqmfq5k+XA\nrqPUm0onfvjIWyYBfm39Qdz3l3WGO2comsDdv1+Nt3ccNfbJVTYUyE7lmji2GXOOGW0KJGptDOH4\ndL1gkXbhZjzFpgNVvovfrk2kGLylqlpQHAA0RoJobgxjxkStytWwpWnIeJuOQFYr3JrGVcy0Li+E\n6ig4ymszCt37MLWjFU2RECanG59UWiEZUjz0cw2YJ+wiTp3AdFZsPISfPLa+4DGEQwHsPTyAXQfz\nt/YVGY4lsGl3N2789lJ87edv1F0EOV3i0Otzmy3je/+sBTus2XIYp6a7EP34r1og2WVnzMCMSW1Y\nsf4g1m0/inXbjxpF6nMFRaRUNSttylpaEtBc13auohOPG4eX3z6IU+Z0mAK4zls0BZPGNmPmpDY8\nvHQrWpvCtlWB2lsbcKrcgfnHjsXo1giefXMPTps7AWuFvOkd6SjQxrB2aejBR1YLW1wvPkXuwMBQ\nHFctORYA8IGLj8fezv4sb4JfDSLGtjdiwaxxWHT8eF8+v5wsnD0OS1dlF75xImS5MZ994mSs2uxc\nIY1UJqNaGrBw1jgsmO39Gv/YP56AlZs6sWDWODz0tAJA87x8+J0yfvF/SrGHCkC7r/wgXRfAC53d\nQ3jgca2u/c4DfejsHsKMSW153lU7ULChWb12NbiBjMUpMhRNYO/hAZPr/FD3EJojIazc5NxNafPu\nbiMXUS8HaVde0ClC99jJo/Ctm84EYF6v/silmWCyr3xEy3sWm2ToBCQJN7/7JOP5wtnjsc5SpUiv\nhKZbw/pYrMvjYuT1mNYIbhGO+45T7YOmGm0s/HIQkCT8v/fVRw1iPT/bLdal6khDEP9yzaIijoiU\ng4Ak4dYCr/ElJ03GkpO0IFJRsM8/eSokKbPNDcdNGZWzmqLOhp1d6HYIWsvFm4o5iLLFIdC0Vqmv\n/9aBI71RPP7yDtvX7JL91247ktXC8vb7XsFJx43LWeJSb0UJaBfaUDThWI4vH/mCNYJ5okZ17ILH\ngEzHn7BDSlRDOIBjJ7dh+/4+W1e7Hblye4k/+BVXQCobfaLutQLgCTPGuBLsQsQaAFZtNhtETpkh\ntUp9/bcCooUqFpqw0tWfneL18roDtvtu2p27IbyIbsGKAv/V6081rR1++cOn5uzT/KV/PtnU0lLE\nqeqXlYljmvGFD5yMiWOa8PkfvQwAmDt9tJGHabX2v/3Js3CkdxgtjWHcdNV8rNt2FKefMMHVZ1Ec\n/OWMeRMxZ1o7WprCkKePwZ5D/baxEIToUedeYxmuPHsmnnhlZ/4dPfKtm87EHT95NWu7X147v6iv\n/1ZAdPOISf5WjvZGcf9j601BGL0O6QzReNKUCgWYOyGJ6OIlThxmTjJHfttFgovI08c4vubWwgZg\nKpwBmF3aVsEeP7oJ49NW+cQxzZh4ivscCzfV1kjpmDt9tKlRR/ux7ppDkPpDL3jk1cIOhwJYNHu8\nkRXjhVBQMlXgE5k41v4+Y1c9rZapyztoIpnCsjX7XO277/AAXnn7AJat2Z9/Z2Rf4HYFRoBMAFap\nKu2FQwG0tzbgvEVTXL/ng5fMwZTxLabiCsXIYT5j3kRMHtdc0b2o6wF+/8QteprYqXMnICBJ+KiL\nWuTTOlogSVLObJXjpozCmfMnYuyoiCkI9eTjxzumpl2WLuLymfecZPt6PVGXgu22yIAds6aOwk+/\ndAGOmaAVHmhpDOHjV2Q60HQL1vcXP3AyrrnweFx59sys4+hBW6Vq6xiQJNx9yxJTQFo+Llw8Dd/4\n+BmmNelipPd84qr5+MbHzxjxccjIoFwTt+iiO3ZUI+7/4vk4Z2H2xP/GK+fhQ5dkKiJ+7YbTAWRb\nvaJ1fNv7F+KmK+fjuzcvwb3/kilO9Zl/WmBY9RefMg2j0oVbzls0Be+7YDYA4OQ5HfjctfUdEFmX\ngj0SGhtCkCTJyHdtCAdNAjdNWBPUAyLsRFm/OEtZy74YFpXoxm51WC8v11iIO5zqQPMcELeIAaJO\n183olgbDKp45qc3Yb8JYcyCrbtwA5tROq7Drz1OqasRWWINi9boQ9UrdrmE7MXFsMxan83VnTW3H\npt3d2HGgzwgo0y/k8aO1wiH9Q3Esmj0e171jDrr7o7hw8TQjnUoXbNFK/ex7F0ACsPwtzcVe6X2Y\nZ09tx/WXzUVn9xDOs5llk8rjjusW481NnRjdGsGU8S34twdfB+C9qhSpP/7t+tOw62Af2l0U4Glv\njWDO9NGIxpJYsiCz9HfV2ceitTGM0+ZOwBsbD+GchVOwYqNWatnq3fz0e04yRDwgrJt/4qr5ePnt\nA7j4FHOKaGtTGDe/60TsPNiH0+a6C3atJYom2LIsBwD8CMACAFEAH1cUZWuxjl8urr1wNhYKxQcW\nz+nA5j3d+NavtBZverCYbmHHEylIkoSLTpmWdSy9sYYuypFwEIvSx34l3XyhGtrFnUuhrirGj27C\nO0/Pbt5QbwE6xDszJrW5LkQyurUBwUAAl1iutUhDEJedOQMAjL9OLJ7TYTw2BFtV0d4awWVn2L/3\n1LkTjGJW9UYxXeLvAtCgKMrZAG4H8L0iHrvoXLVkpu326TYul7FtQtnQ9NrKGelUJrFdnc6cdFlR\nXdzPnD8RAPD+C2cb+5yzQBPBfBc0ISNFj/q3K3dLiFtmT9WuHz2rxG39BUCrxObUaETnqnSszxnz\nJhU2wDpAKpaFJ8vy9wC8pijKw+nnexRFyTY7AXR29vluVqqqClXVLORkSkVjJIhEIoUGm+Ieqqri\nY/+1FABw4xXzcNaJ2gU1dmwLjhzpz1rjSakqksmUqehISlUhwbweFIsnbT+PeKejow2dnX1+D6Ni\nKee1xnNRWRTrfOj3tVAwABXePDYJoe1wLmr9ntjR0TYiN1cxLexRAMQSN8m0m7wikSQJgYCESEMQ\nzY0hBCTJ8UIRRXZqRyaoLBgM2AZkBCQpq0JYQJKy9q3lC5NUFrzWyEjR72vWNrpuCAUDrrJzeJ3m\npphBZ70ARH9yQFEU204YI51l+MFj37vadntHR31HLVYSPBeVA89FZcHzURsU0wJeDuByAJBl+UwA\na4t4bEIIIaSuKaaF/WcA75BlWW8R9dEiHpsQQgipa4oWdEYIIYSQ0lGxQWGEEEIIyUDBJoQQQqoA\nCjYhhBBSBVCwCSGEkCqAzT8ckGX5IwCuTz9tArAQwERFUXplWf4+gI2KovzY8p4wgIcAzACQBHCj\noihK+UZdmzicizMB/BBAAlrt+g8rinJIeE9N1LavNAo8F2EAD0L7XUQAfENRlMfKOOyapJBzIbx3\nAoA3AVykKMqmsgy4hin0XMiyfAeAKwE0APiRoigP5vocWtgOKIrykKIoFyiKcgGAFQA+A6BBluWn\noH3BduH1lwMIKoqyBMB/APhm2QZcwzicix8AuCW97REAX7K8rapq21cLBZ6L6wB0KopyLoBLod3E\nyAgp8FzoE6gfAxgo53hrmULOhSzL5wM4K32POg+AuTWZDRTsPMiyfCqA+YqiPACgFcC/AfglALtq\nbQqAkCzLEoB2ALGyDbQOsJyLaxVF0YvzhAEMWXZfAuBpAFAU5TUAp5ZtoHWAx3PxBwBfTT8OQLM4\nSJHweC4A4DsA/hfA/jINsW7weC4uAfCWLMuPAngMwOP5jk+XeH7uBPDvAKAoyg4AO2RZvsxh3wEA\nMwFsBDAewBWlH15dIZ6LAwAgy/LZAG4BcI5lX9va9k7lcolnXJ8LRVEG0q+3QRPvfy3nQOsA1+dC\nluXroXk7nkm7Y6uuTHSF4+Ue1QHNqr4CwHEA/gpgbq6D08LOgSzLowHMURTlBZdvuQ3A04qiyNDW\nMB6SZbmhZAOsI+zOhSzL10CzFC5XFOWI5S2ua9sTbxRwLiDL8jEAngPwC0VRfle2wdY4BZyLj0Kr\nSLkUwCJo96iJZRtwDVPAuTgM4BlFURLpOIJhWZbH5/oMWti5ORfAsx72Pwognn7cBc0NwvYzxcF0\nLmRZ/iCAmwCcryhKl83+y6HFGvyBte2LjqdzkRaEZwDcrCjK0rKNsj7wdC4URTlP2HcpgE8oinKw\nHAOtA7zeo14CcCuAu2VZngKgBUDWZFeEFnZu5gBwiiw2gs5kWX5IluVpAL4PYLEsy8ugnbg7FEWx\nW0Mi3jHOhSzLQWgBHa0AHpFleaksy/+Wfk0/F3+GNmNdDi3g7DZ/hl2TeDkXxwC4A1pMx1fTry+V\nZbnRp7HXGl7PBSkdnu5RiqI8AWCVLMuvQ3OH36woSs5a4awlTgghhFQBtLAJIYSQKoCCTQghhFQB\nFGxCCCGkCqBgE0IIIVUABZsQQgipAijYhBBCSBVAwSaEEEKqgP8PJnq2ftFe/FwAAAAASUVORK5C\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x111f71ed0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "timestep = 0.001 ##the time resolution for the light curve\n",
    "lc = Lightcurve(data[:,0], timestep=timestep)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(lc.time, lc.counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There you go, it's a burst. The class `Lightcurve` has several useful attributes. Have a look at the code if you're interested. It works both with time tagges arrival times (in which case it takes a value `timestep` for the output time resolution) or with counts, in which case you should use the keyword `times` for time bins and `counts` for the counts per bin.\n",
    "\n",
    "The next step is to make a periodogram. This is easy if we already have a `Lightcurve` object.\n",
    "Note that we'll use `loglog` for the figure rather than `plot`, because the spectrum is better plotted on a log-log scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1120556d0>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe8AAAFdCAYAAAAqi+WzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAF4pJREFUeJzt3V+IZNd9J/DvTMzIf+jsw6QQyVNgshy8gZEhw0oe9KLx\nypCA8CChNYF4jQZZrEKwBc4OA0tsvGFxI3u8ehIkcgaDNk/DSpg4oKd52gkWa8JqXswBDegtccaC\n3VEIKyOp96GrpZpW/6k/91bdU/X5gOmu0q17T9Xc9rd+5557zomdnZ0AAO04ueoGAACzEd4A0Bjh\nDQCNEd4A0BjhDQCNEd4A0Jhew7uUcn8p5X/1eQwA2DS9hXcp5USS/5Tkrb6OAQCbqM/K+z8m+e9J\n/l+PxwCAjfOJeV5USnkwyXat9ZFSyskkLyY5m+TdJE/XWm8n+Xfj5/5tKeWJWuv/6KrRALDJZq68\nSymXk7yU5L7xUxeTnKq1nk9yJcnVJKm1PlFrfTbJ64IbALozT7f5m0keT3Ji/PjhJK8lSa319STn\nJjeutf6HRRoIANxr5vCutb6S5L2Jp7aS3J14/P64Kx0A6MFc17z3uZvdAN9zstb6wSw72NnZ2Tlx\n4sTxGwLA+pg7+LoI75tJHktyvZTyUJJbs+7gxIkTuXPnnQ6aArtGoy3nFJ1yTtG10Wjr+I0OsUh4\n7y0E/mqSR0spN8ePn1pgnwDAMU7s7Owcv1X/dnyjpUuqJLrmnKJro9HW3N3mBpYBQGOENwA0RngD\nQGOENwA0RngDQGOENwA0RngDQGOENwA0RngDQGOENwA0RngDQGOENwA0poslQTfSC9ffyK3bb3ey\nr7NnTue5Jx/oZF8ArD+V9wB09SUAgM2g8p5TV5Xype0bnewHgM2h8gaAxghvAGiM8AaAxghvAGiM\n8AaAxghvAGiM8AaAxghvAGiM8AaAxghvAGiM8AaAxghvAGiM8AaAxghvAGiM8AaAxghvAGjMJ1bd\nADjMC9ffyK3bb0+17dkzp/Pckw/03CKAYVB5M1jTBves2wK0rrfKu5Tye0n+JMmJJJdrrf/U17HW\nwaXtG70fo9Xq9NqVC0f+92V8dgBD0mflfV+S55L8bZLP93icpp09c3ppx1KdAqyH3irvWuvflVI+\nn+RPk/z7vo7TumVVwqpTgPUxV3iXUh5Msl1rfaSUcjLJi0nOJnk3ydO11tullHNJfpbk95N8O8k3\nOmozAGy0mbvNSymXk7yU3W7xJLmY5FSt9XySK0mujp//9STXknwvyV8v3lQAIJmv8n4zyeNJXh4/\nfjjJa0lSa319XHGn1nojib5aAOjYzJV3rfWVJO9NPLWV5O7E4/fHXekAQA+6GLB2N7sBvudkrfWD\nWXcyGm0dvxELW+Xn/J0f/jQ/+/kvZn7dtG3ev51ziq45pxiKLsL7ZpLHklwvpTyU5NY8O7lz550O\nmsJxVvk5zxPcZ8+cnrrNk9uNRlvOKTrlnKJri3wZXCS8d8Y/X03yaCnl5vjxUwvskw1w3KQrfThu\nqtVWJ7ABNtNc4V1rfSvJ+fHvO0me7bBN0LnjJqgxgQ3QEguTbJiuJmtptVI9qOo3gQ3QGqPCN0TX\n07CqVAFWR+W9IbqsklWqAKul8gaAxghvAGiM8AaAxrjmzdxc+wZYDZU3M1tk5HrXo94BNpHKm5m1\neH/3NA7rSWj1nnZgfam82XjH9Qa4px0YGpU3G++oqtp1fWCIVN4A0BiVN6zAQaucubYOTEvlDStw\n0HV019aBaQlvWKFrVy6sZH1zoG26zVkbBpcBm0LlTfOmnfjFBDHAulB507yDBnmNRlu5c+edFbQG\noH8qbwBojPAGgMYIbwBojPAGgMYIbwBojPAGgMYIbwBojPAGgMaYpAUGZP8Ur1YaAw6i8oYBOGzq\nViuNAQdRecMAHFRdW2gFOIzKGwAaI7wBoDHCGwAa45o38DEvXH/jw8FyRrzD8PQW3qWULyT5cpJP\nJ3m+1nqrr2MB3Zoc5W7EOwxPn93mn6q1PpPk+0m+2ONxAGCj9FZ511p/Ukr5TJKvJ7nc13GAe012\neSe6vWEdzRXepZQHk2zXWh8ppZxM8mKSs0neTfJ0rfV2KeU3kjyf5Fu11l921mLgSPu7uXV7w/qZ\nudu8lHI5yUtJ7hs/dTHJqVrr+SRXklwdP381yf1JvltKeaKDtgIzuHblwqqbAPRknsr7zSSPJ3l5\n/PjhJK8lSa319VLKufHvX+2khdCQ/V3We3RdA12aufKutb6S5L2Jp7aS3J14/P64Kx02zmFd1Lqu\ngS51MWDtbnYDfM/JWusHs+5kNNo6fiOYQZfn1EHzjJ/77P359tMPHbj931z90oe/P/bNHx/anmna\nOO/7mHzdop+Fv89dPgeGoovwvpnksSTXSykPJZnrfu47d97poCmwazTa6uScOnvm9KFV889+/otD\nj3HQ89M+N882x71u0c/C32d35xTsWeTL4CLhvTP++WqSR0spN8ePn1pgnzAoh12nnmfFL6uEAV2Z\nK7xrrW8lOT/+fSfJsx22CdbKYdX7YWt4AxzH3ObQs3UfZW4edFg+4Q3M5aDb4oyqh+VwSxcwl/1T\nsALLI7yBhVy7ckFXOSyZbnMYuL1R6q4nA3uENwzU/lHqt26/fc/tZssMc7e5wbAIbxioyWBe1eCw\noyap2fvvwPIJb2jA/gp7WZVwH5X93hcRlwFgfgasAUu1V8m7rQzmp/KGhq3qGvhRLm3f6LQtJoGB\nj1N5Q4MOutZ8VCV7aftGLm3fyAvX31hKm7qsqvcP2gNU3tCkaa+BHzRive82GZkO/RPesMYmQ16o\nwvrQbQ70ou9uethkwhvo1P5r30IcuqfbHEhy8EQw89jrqp/c363bb3e2f0DlDYztD9ZFZ0977skH\ncu3KhUP3n+hah3mpvIF7TAZuX/vfX5UDs1F5A0u3vyoHZiO8AaAxwhsAGiO8gaYY4AbCG2jE3uh3\nA9xAeAONWPVqYt/54U/d2sZgCG+AKfzs579IovJnGNznDTC2d/+5dcMZOpU3wJiJY2iFyhsWYJnN\n7ql+Z+cz2zwqb5jDUfN+Lzon+KZT/c7OZ7Z5VN4wh5arm73eghaqtMN6Ni5t35i6/apS1pHwhg1x\n9szpeyqzIVVpkwF7kL3nJ9/DtO1XlbKOhDdsiMmqc2jX6g8K2IMWLtl7D0NrPyyba94A0Jjew7uU\ncqGU8lLfxwGATdFrt3kp5UySzyX5ZJ/HAdbLUEbsH3ctftF9GkDHvHoN71rr7SQ/KKW83OdxgOGa\nHGR2XAgedJ37KLOMOp80TYDubZMsNtht/7EMoJvP3jiHWc+RdTV3eJdSHkyyXWt9pJRyMsmLSc4m\neTfJ0+PgBjZc39XlPCE4TYB2Fa7Cmj7Mdc27lHI5yUtJ7hs/dTHJqVrr+SRXklztpnkAwH7zDlh7\nM8njSU6MHz+c5LUkqbW+nuTc5Ma11q/M20AA4F5zdZvXWl8ppfz2xFNbSe5OPH6/lHKy1vrBtPsc\njbbmaQocahPPqcn3PM37P2ibZX5u5z57/4dLbZ777P1zH3va1x32fr/zw59+2I4uj3fc6/r4rIdw\n3j/2zR8nSf7m6pc63/cQ3t8QdDVg7W52A3zPTMGdJHfuvNNRU2D3D3wTz6nJ9zzN+z9om2V+bn/8\npd9NvvS7Cx972tcdtN1/fvF/znw9uqt29vFZD+m8X/f3t6hFvoh0Fd43kzyW5Hop5aEktzraL9Cj\nyXnON1WfA8mGNhPc/lvfjhtxb4T3cC0a3jvjn68mebSUcnP8+KkF9wv0aMjznNOfg0a+d/FvL+SX\nb+7wrrW+leT8+PedJM921CagZ0Oe53xdvHD9jVU3YTCEe/fMbQ7QgxZ7My5t3/BlrhHCG6BBgnaz\nWRIUYML+8QAHWff5yYf8peCF62+s5Wc+K5U3wNi1KxemCoaupjx1Xfx4+3sYWrwc0QfhDWysaW6R\n6/M2OkHEvIQ3rJF5ujsnw6nl+71fuP5GLm3fmKmanabK1kX7cYteb5/m9dMeY55/93Xgmjesgf3X\naWcJ4XUIp1a6VfsImE0Lrf02ddU24Q1rYB0CeBNMrms+bdgcNzhu/34ubd848H7qVYX8pn+56Itu\nc2AttDQByFHTke7vKp6nsjyou3lVlemmVcTLIryBtaPaG4Yh33LWOt3mwNrY645edrW3yPSf+xcL\n6VLX05IK4+FQeQNro69r/9euXOhlbepkcwdcsRjhDUBT9AAIbwCWyHiEbghvgH32rj/Peh1aMB1f\nFR90a5tKenYGrAHN63qw1yzXzicDe1nXrYUdwhto2qrv7zbQrFu+mExHeAPQXGi21t6uueYNMKXD\nuueP6rZfdc9A32a5zr/pgdsl4Q00Z9oBZfuDZW8Fqnkddi18k+eW7/KygXCfnm5zoDnThOWQ5vdu\n3aXtGwd+UepydL3gno3wBtbaLCt4dWFdQ+igz3D/c26VWx7hDaytvevNQwzUo75UDLG905j1S1Kr\n73MIXPMGWIFNvk7O4oQ3ADRGeAM0Yv815T6WEaUNwhvYSEMKvmnbsv+asq73zWXAGrBRhjhpynNP\nPmDwFjNReQM0ZNrbsXwZWG/CG6Ahe13nQ+r2Z/mEN7D25l2fe8hc795srnkDa0/QsW5U3gDQmN7C\nu5RyvpTyo/H//lVfxwEYumV11x82kt6c4+unz8r7a0meSfJXSb7c43EABm2abvs+A95qauunz/D+\ntVrrr5L8Q5Lf7PE4ACvTVeg+9+QDg7wHnWGaa8BaKeXBJNu11kdKKSeTvJjkbJJ3kzxda72d5F9K\nKaeS/FaSf+yqwQBDYjAcqzBz5V1KuZzkpST3jZ+6mORUrfV8kitJro6f/8skf5Hd7vOXF28qAJDM\nV3m/meTxfBTIDyd5LUlqra+XUs6Nf//7JE910UiAoThqHe4W9s96mDm8a62vlFJ+e+KprSR3Jx6/\nX0o5WWv9YJb9jkZbszYFjuScYtZz4LjtR6Ot/Nc/fjhJ8tg3fzz1a457bvLx/v0vst9prcvfyrq8\nj2l0MUnL3ewG+J6ZgztJ7tx5p4OmwK7RaMs5xcznwFHbH3ZOHXeMaV4zz7l62H6nrdyvXbnw4fzn\nx31RaEVrf/OLfNnoYrT5zSR/kCSllIeS3OpgnwBzWdVUqEOZgtUAus2wSOW9M/75apJHSyk3x49d\n5wZWZlXhNXlcK3p9ZLLCpztzhXet9a0k58e/7yR5tsM2ATRtr+t61VU468vCJAAd03VN3yxMAjBA\nqnaOIrwBBmja6n0oA+UOMsQ2rQvd5gAr0sVc5geF/FAmenH5oD8qb4CBmzXkW1vkpKW2DoXwBoDG\nCG8AaIzwBmBuBqWthvAGmMO1Kxdcq81yB6X5vD8ivAH40KoqacE8G+ENbLQh3yc9aVnt2xup3srn\nsqnc5w1stFbuRX7uyQeWusCHhVaGTeUNAI0R3gCNcF2YPcIbgEHxJeV4whuAZm1q0AtvADpnlHq/\njDYHoFObWg0vk8obABojvAGgMcIbABojvAEGyuInH+fz2CW8AaAxwhsAGiO8AaAxwhuAzpicZTmE\nNwCdaWWJ1dYJbwBojPAGgMYIbwBojPAGWFMmNFlfwhuAmRhRvnq9hncp5UIp5aU+jwHA4bqeYvXa\nlQtGlA9Ab+t5l1LOJPlckk/2dQyAVpw9czq3br+98qp1KF3pe58H8+ktvGutt5P8oJTycl/HAGiF\navVezz35QC5t31h1M5o1U3iXUh5Msl1rfaSUcjLJi0nOJnk3ydO11tullD9P8jtJnq21/p/OWwzA\nUg2l14CPTB3epZTLSf4oyT+Pn7qY5FSt9fw41K8muVhr/bPumwnAqug1GJ5ZKu83kzyeZK8b/OEk\nryVJrfX1Usq5g15Ua/3KQi0EYHCGcu18U0092rzW+kqS9yae2kpyd+Lx++OudAAa0PVIdJZnkQFr\nd7Mb4HtO1lo/mHdno9HW8RvBDJxTdG1I59S8bTnudYu+x2lfP7nd/tccto+Dnj9qP+tskfC+meSx\nJNdLKQ8lubVIQ+7ceWeRl8M9RqMt5xSdGto5NW9bjnvdou9x2tdPbrf/NYft46Dnj9rP0C3yZWOe\n8N4Z/3w1yaOllJvjx0/N3QoAYGozhXet9a0k58e/7yR5toc2AQBHMMAMABrT2wxrANCF40bEb+Lk\nMcIbYAOs8y1hmziJjG5zAGiMyhuApVnnHoBlUnkDQGOENwA0Rrc5QEN0O5OovAGgOcIbABojvAGg\nMcIbABojvAGgMcIbABojvAGgMcIbABojvAGgMcIbYMPtrYe9ietit8r0qAAbbhPXw26dyhsAGqPy\nBmAlLLIyP5U3ADRGeANAY4Q3ADRGeANAY4Q3AAtxn/jyGW0OwELcJ758Km8AaIzwBoDGCG8AaIzw\nBoDGCG8ABssUqgcT3gDQmF5uFSulfCHJl5N8OsnztdZbfRwHADZRX5X3p2qtzyT5fpIv9nQMANhI\nvYR3rfUnpZTPJPl6kh/1cQwA2FRTd5uXUh5Msl1rfaSUcjLJi0nOJnk3ydO11tullD9P8jtJvpFk\nO8m3aq2/7KHdALCxpqq8SymXk7yU5L7xUxeTnKq1nk9yJcnVJKm1/lmt9Q+TfC/J/Um+W0p5ovNW\nA8AGm7byfjPJ40leHj9+OMlrSVJrfb2Ucm5y41rrVztrIQBwj6kq71rrK0nem3hqK8ndicfvj7vS\nAYCezXur2N3sBviek7XWDxZpyGi0dfxGMAPnFF1zTi1ums9wcpvjtt/Uf5N5w/tmkseSXC+lPJRk\n4fu479x5Z9FdwIdGoy3nFJ1yTnVjms9wcpvjtm/532SRLx6zhvfO+OerSR4tpdwcP35q7hYAwD5H\nTYt69szp3Lr9ds6eOb3EFg3L1OFda30ryfnx7ztJnu2pTQBwqOeefGDVTVg5g8wAoDHCGwAaI7wB\noDHCGwAaI7wBoDHCGwAaI7wBoDHCGwAaI7wBoDHCGwAaI7wBoDHCGwAaI7wBoDHCGwAaI7wBoDHC\nGwAaI7wBoDHCGwAaI7wBoDHCGwAaI7wBoDHCGwAaI7wBoDHCGwAaI7wBoDHCGwAaI7wBoDHCGwAa\nI7wBoDHCGwAaI7wBoDHCGwAaI7wB6NXZM6fv+cniTuzs7HS+01LK7yX5kyQnklyutf7TMS/ZuXPn\nnc7bweYajbbinKJLzim6NhptnZj3tX1V3vcleS7J3yb5fE/HAICN1Et411r/Lsm/SfKnSf53H8cA\ngE31iWk3LKU8mGS71vpIKeVkkheTnE3ybpKna623Syn/Jcm/TvLfkvwsye8n+XaSb3TecgDYUFOF\ndynlcpI/SvLP46cuJjlVaz0/DvWrSS7WWr813v5CkmtJfpXkLzpvNQBssGkr7zeTPJ7k5fHjh5O8\nliS11tdLKecmN6613khyo6tGAgAfmeqad631lSTvTTy1leTuxOP3x13pAEDPpr7mvc/d7Ab4npO1\n1g8WaMeJ0Wjr+K1gBs4puuacYijmrZZvJvmDJCmlPJTkVmctAgCONGvlvTejy6tJHi2l3Bw/fqq7\nJgEAR+llhjUAoD8GmQFAY4Q3ADRGeANAY+a9VaxXpZTzSZ4ZP/xGrfX/rrI9rIfxzH9/WGv92qrb\nQvtKKV9I8uUkn07yfK3VXTfMbdbVOIdaeX8tu+H9V9n944CFlFLOJPlckk+uui2sjU/VWp9J8v0k\nX1x1Y2jeTKtxDjW8f63W+qsk/5DkN1fdGNpXa71da/3BqtvB+qi1/qSU8pkkX0/yoxU3h8bNuhrn\n0rvNp1mdLMm/lFJOJfmtJP+47DbSlinPKZjalKso/kaS55N8q9b6yxU2l4Gb8nw6lxlW41xq5T1e\nneyl7HYPJBOrkyW5kt3VyZLkL7O7GtnX8tFiKPAxM5xTMJUZzqmrSe5P8t1SyhNLbyhNmOF8+vXs\nrsb5vSR/fdx+l115T7U6Wa3172PWNqYz64p3X1lu82jQtP8/9dXVNI/GTHs+zbQa51Irb6uT0TXn\nFF1zTtGlvs6nVZ+AXa9OBs4puuacokudnE+rDm+rk9E15xRdc07RpU7Op1VN0mJ1MrrmnKJrzim6\n1On5ZFUxAGjMqrvNAYAZCW8AaIzwBoDGCG8AaIzwBoDGCG8AaIzwBoDGCG8AaIzwBoDGCG8AaMz/\nBwGbpTFMXxLvAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x112355810>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ps = PowerSpectrum(lc, norm=\"leahy\")\n",
    "\n",
    "plt.loglog(ps.freq[1:], ps.ps[1:], lw=2, linestyle=\"steps-mid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `PowerSpectrum` class comes with three normalizations built-in: `leahy` for the Leahy normalization, `rms` for a rms-normalized periodogram and `variance` for a periodogram that is normalized to the total variance.\n",
    "\n",
    "For most purposes here, the Leahy normalization (default) is probably what you want, but the other options are there if you want them.\n",
    "\n",
    "## ML/MAP Fitting\n",
    "\n",
    "So far, we haven't actually done any analysis. Let's first talk about models.\n",
    "All parametric models are saved in the model `parametricmodels.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from BayesPSD import pl, bpl, const, qpo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now, for example, fit one of these models to the data.\n",
    "This kind of fitting is implemented in the class `PerMaxLike`, which, despite its name\n",
    "actually usually does maximum-a-posteriori estimates rather than maximum likelihood estimates.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from BayesPSD import PerMaxLike\n",
    "\n",
    "psfit = PerMaxLike(ps, obs=True, fitmethod=\"bfgs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`PerMaxLike` takes a `PowerSpectrum` object. The variable `obs` controls whether output plots and logs are produced (set True if you want those!) and `fitmethod` sets one of the optimization algorithms specified in scipy.optimize.\n",
    "My recommendation is to set to `bfgs` unless you have a good reason not to.\n",
    "\n",
    "In order to actually fit a model to the periodogram, we'll need to specify what model, and will also have to set starting guesses for the parameters. Note that the number of parameters. Look at the function definitions for details about the different models. In the case below, we'll use a simple power law model, which takes the power law index, the log(amplitude) and log(background).\n",
    "\n",
    "The actual fitting is implemented in method `mlest`. For details on all parameters this method takes, see the documentation. Below are the most important ones. Again, we can set whether the code should produce plots and be verbose, and we can set whether the periodogram we use is the simple Fourier transform of a light curve (m=1) or whether it is the average of several periodograms (or frequency bins). \n",
    "If `map` is True, the code will produce the maximum-a-posteriori estimate, otherwise it'll return a Maximum Likelihood estimate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient and/or function calls not changing!\n",
      "Approximating covariance from BFGS: \n",
      "Covariance (empirical): [[ 0.02036338  0.0781775   0.0117943 ]\n",
      " [ 0.0781775   0.31121761  0.041365  ]\n",
      " [ 0.0117943   0.041365    0.01405316]]\n",
      "The best-fit model parameters plus errors are:\n",
      "Parameter 0: 2.08723748958 +/- 0.142700328632\n",
      "Parameter 1: 11.1100661977 +/- 0.557868814871\n",
      "Parameter 2: 0.457427143928 +/- 0.118546023877\n",
      "The Akaike Information Criterion of the power law model is: 887.00711241.\n",
      "The figure-of-merit function for this model is: 359.736396168 and the fit for 368.0 dof is 0.977544554804.\n",
      "Fitting statistics: \n",
      " -- number of frequencies: 371\n",
      " -- Deviance [-2 log L] D = 1762.01422482\n",
      " -- Highest data/model outlier 2I/S = 13.5363506735\n",
      "    at frequency f_max = 450.940860213\n",
      " -- Highest smoothed data/model outlier for smoothing factor [3] 2I/S = 7.5281022425\n",
      "    at frequency f_max = 452.284946234\n",
      " -- Highest smoothed data/model outlier for smoothing factor [5] 2I/S = 5.91861983855\n",
      "    at frequency f_max = 450.940860213\n",
      " -- Highest smoothed data/model outlier for smoothing factor [11] 2I/S = 4.02380352683\n",
      "    at frequency f_max = 8.73655913974\n",
      " -- Summed Residuals S = 741.99999352\n",
      " -- Expected S ~ 2226.0 +- 66.7233092704\n",
      " -- KS test p-value (use with caution!) p = 0.685345492809\n",
      " -- merit function (SSE) M = 359.736396168\n"
     ]
    }
   ],
   "source": [
    "## starting parameters\n",
    "pars = [2,10,np.log(2.0)]\n",
    "\n",
    "fitparams = psfit.mlest(pl, pars, obs=True, m=1, map=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fitting routine returns a dictionary with lots of interesting and useful information. Let's have a look at the dictionary keys:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['maxind', 'smooth3', 'smooth5', 'merit', 'result', 'popt', 's11maxfreq', 'maxpow', 's5maxfreq', 's5max', 's3max', 's11max', 's3maxfreq', 'bindict', 'maxfreq', 'bic', 'sexp', 'smooth11', 'ssd', 'ksp', 'err', 'deviance', 'cov', 'dof', 'mfit', 'sobs', 'model', 'aic']\n"
     ]
    }
   ],
   "source": [
    "print(fitparams.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the most interesting ones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best-fit parameters are [  2.08723749  11.1100662    0.45742714]\n",
      "The covariance matrix for the parameters is: [[ 0.02036338  0.0781775   0.0117943 ]\n",
      " [ 0.0781775   0.31121761  0.041365  ]\n",
      " [ 0.0117943   0.041365    0.01405316]]\n",
      "The MAP estimate (or Maximum Likelihood estimate) is 881.007\n",
      "The deviance (-2*log(maximum likelihood)) is 1762.014\n",
      "The Akaike Information Criterion is 887.007.\n",
      "The Bayesian Information Criterion is 1994.007.\n"
     ]
    }
   ],
   "source": [
    "print(\"The best-fit parameters are \" + str(fitparams[\"popt\"]))\n",
    "print(\"The covariance matrix for the parameters is: \" + str(fitparams[\"cov\"]))\n",
    "print(\"The MAP estimate (or Maximum Likelihood estimate) is %.3f\"%fitparams[\"result\"])\n",
    "print(\"The deviance (-2*log(maximum likelihood)) is %.3f\"%fitparams[\"deviance\"])\n",
    "print(\"The Akaike Information Criterion is %.3f.\"%fitparams[\"aic\"])\n",
    "print(\"The Bayesian Information Criterion is %.3f.\"%fitparams[\"bic\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A side note: likelihoods, priors and posteriors are implemented in `Posterior` and its subclasses. \n",
    "Currently (fairly uninformative) priors are hard-coded. If you need different priors, my suggestion is to fork the repository and implement them in a separate branch. Or you could subclass Posterior to make your own.\n",
    "\n",
    "## Bayesian QPO Detection\n",
    "\n",
    "So now comes the fun bit: we can do the actual QPO search! Most of that is implemented in the class `Bayes`. Its constructor takes a `PowerSpectrum` object and various parameters: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from BayesPSD import Bayes\n",
    "\n",
    "bb = Bayes(ps, namestr='demo', plot=True, m=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The variable `namestr` allows you do set a string identifier for all output plots and text files. This is especially useful if you run many bursts and need to save each in its own separate file.\n",
    "\n",
    "The variable `plot` controls whether the code produces output plots for diagnostic purposes. This is usually a useful feature to leave on. \n",
    "\n",
    "Finally, the periodogram we just produced above is a simple Fourier transform of a single light curve. However, in some applications, you might want to average periodograms or frequency bins, in which case the statistical distributions used in the likelihood need to change. Set `m` to the number of periodograms or frequency bins averaged.\n",
    "\n",
    "\n",
    "There will be two steps: First, we need to make some statement about what kind of model to use for the broadband noise (that annoying lower-law-shaped component in the plot above). In the second step we'll use that broadband noise model to infer the presence of a QPO.\n",
    "\n",
    "Note that unless you care in detail whether you are using the parsimonious model, you can skip step (1) and just use a more complex model. We'll demonstrate the functionality here anyway."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approximating covariance from BFGS: \n",
      "Covariance (empirical): [[ 0.03253482  0.13130155  0.01009341]\n",
      " [ 0.13130155  0.54188035  0.03744738]\n",
      " [ 0.01009341  0.03744738  0.00901978]]\n",
      "The best-fit model parameters plus errors are:\n",
      "Parameter 0: 2.08723754207 +/- 0.180374112506\n",
      "Parameter 1: 11.1100663176 +/- 0.736125223821\n",
      "Parameter 2: 0.457427265489 +/- 0.0949725030814\n",
      "The Akaike Information Criterion of the power law model is: 887.00711241.\n",
      "The figure-of-merit function for this model is: 359.736373665 and the fit for 368.0 dof is 0.977544493654.\n",
      "Fitting statistics: \n",
      " -- number of frequencies: 371\n",
      " -- Deviance [-2 log L] D = 1762.01422482\n",
      " -- Highest data/model outlier 2I/S = 13.5363495029\n",
      "    at frequency f_max = 450.940860213\n",
      " -- Highest smoothed data/model outlier for smoothing factor [3] 2I/S = 7.52810159015\n",
      "    at frequency f_max = 452.284946234\n",
      " -- Highest smoothed data/model outlier for smoothing factor [5] 2I/S = 5.91861932672\n",
      "    at frequency f_max = 450.940860213\n",
      " -- Highest smoothed data/model outlier for smoothing factor [11] 2I/S = 4.0238035013\n",
      "    at frequency f_max = 8.73655913974\n",
      " -- Summed Residuals S = 741.999976503\n",
      " -- Expected S ~ 2226.0 +- 66.7233092704\n",
      " -- KS test p-value (use with caution!) p = 0.685345233619\n",
      " -- merit function (SSE) M = 359.736373665\n",
      "Gradient and/or function calls not changing!\n",
      "Approximating covariance from BFGS: \n",
      "Covariance (empirical): [[ 0.38054755  0.23509512  0.68112036  1.2383846  -0.01812769]\n",
      " [ 0.23509512  0.31074405  0.23346897  0.53388234 -0.02790734]\n",
      " [ 0.68112036  0.23346897  1.52872923  2.53538571 -0.00838119]\n",
      " [ 1.2383846   0.53388234  2.53538571  4.39645654 -0.03488924]\n",
      " [-0.01812769 -0.02790734 -0.00838119 -0.03488924  0.00595677]]\n",
      "The best-fit model parameters plus errors are:\n",
      "Parameter 0: 1.18492034413 +/- 0.6168853646\n",
      "Parameter 1: 9.05996213796 +/- 0.557444211711\n",
      "Parameter 2: 2.87967378908 +/- 1.23641790086\n",
      "Parameter 3: 3.32810167723 +/- 2.09677288761\n",
      "Parameter 4: 0.610094126788 +/- 0.077180137587\n",
      "The Akaike Information Criterion of the power law model is: 888.151939903.\n",
      "The figure-of-merit function for this model is: 358.350560945 and the fit for 366.0 dof is 0.979099893291.\n",
      "Fitting statistics: \n",
      " -- number of frequencies: 371\n",
      " -- Deviance [-2 log L] D = 1756.30387981\n",
      " -- Highest data/model outlier 2I/S = 14.5414216556\n",
      "    at frequency f_max = 187.499999999\n",
      " -- Highest smoothed data/model outlier for smoothing factor [3] 2I/S = 7.03906642037\n",
      "    at frequency f_max = 452.284946234\n",
      " -- Highest smoothed data/model outlier for smoothing factor [5] 2I/S = 5.53651404424\n",
      "    at frequency f_max = 450.940860213\n",
      " -- Highest smoothed data/model outlier for smoothing factor [11] 2I/S = 5.03531944576\n",
      "    at frequency f_max = 8.73655913974\n",
      " -- Summed Residuals S = 741.999930018\n",
      " -- Expected S ~ 3710.0 +- 86.1394218694\n",
      " -- KS test p-value (use with caution!) p = 0.518561094036\n",
      " -- merit function (SSE) M = 358.350560945\n",
      "The Likelihood Ratio for models pl and bpl is: LRT = 5.71034501353\n",
      "<--- self.ps len MCMC: 372\n",
      "mcobs topt: [  2.08723754  11.11006632   0.45742727]\n",
      "mcobs tcov: [[ 0.03253482  0.13130155  0.01009341]\n",
      " [ 0.13130155  0.54188035  0.03744738]\n",
      " [ 0.01009341  0.03744738  0.00901978]]\n",
      "The ensemble acceptance rate is: 0.645675\n",
      "The autocorrelation times are: [ 22.78014765  19.8861061    8.41579636]\n",
      "Computing Rhat. The closer to 1, the better!\n",
      "The Rhat value for parameter 0 is: 1.11267027149.\n",
      "Good Rhat. Hoorah!\n",
      "The Rhat value for parameter 1 is: 1.11351293115.\n",
      "Good Rhat. Hoorah!\n",
      "The Rhat value for parameter 2 is: 1.12341978903.\n",
      "Good Rhat. Hoorah!\n",
      "I am on parameter: 0\n",
      "I am on parameter: 1\n",
      "I am on parameter: 2\n",
      "Covariance matrix (after simulations): \n",
      "\n",
      "[[ 0.01657319  0.0638698   0.00924385]\n",
      " [ 0.0638698   0.25784259  0.03139039]\n",
      " [ 0.00924385  0.03139039  0.01365447]]\n",
      "-- Posterior Summary of Parameters: \n",
      "\n",
      "parameter \t mean \t\t sd \t\t 5% \t\t 95% \n",
      "\n",
      "---------------------------------------------\n",
      "\n",
      "theta[0] \t 2.03806506762\t0.128735307425\t1.83456227417\t2.25762551716\n",
      "\n",
      "theta[1] \t 10.91334587\t0.507775682627\t10.11232673\t11.7900667207\n",
      "\n",
      "theta[2] \t 0.426070252098\t0.11685086183\t0.223023084571\t0.605114941126\n",
      "\n",
      "N: 3\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "simulated srat: [741.99998897349474, 741.99997713011589, 742.00002246275267, 741.99997544372536, 741.99998528240474, 742.00002070591984, 742.00001163754837, 741.99995983107488, 741.99999018000608, 741.99997877771341, 742.00001161762191, 741.99999811057933, 742.00002443198809, 742.00002005777947, 741.99995971143903, 741.99998978388908, 742.00003039424746, 741.9999919540171, 741.99999662422465, 742.00000230872001, 741.99998201956896, 741.99999700926571, 741.99996798657503, 742.00001520303795, 741.99997371368477, 742.00000152459234, 741.99999397895726, 741.99999357964566, 741.99999725562066, 742.00003030325774, 741.99997903200415, 742.00000603351987, 741.99999966932148, 741.9999765863638, 741.99997888384382, 741.99999239702561, 741.99998889741596, 742.00004058963941, 741.99998479162809, 741.99999040866487, 741.99999818779042, 741.99998315190112, 741.99999343387321, 742.00002315430618, 741.99999852482642, 741.99999380685063, 741.99999960673063, 742.00000136592257, 741.99998156322863, 742.00000160767854, 742.00000210505596, 741.99999020968608, 741.99998027462209, 742.00000385584599, 742.00002989389964, 742.00000581597487, 741.99999932305718, 742.00000201605008, 742.00001295574395, 741.99998669523347, 742.00000196272026, 742.00000810846996, 742.00000284519058, 741.99998212053993, 741.99997823747003, 741.99999926173234, 742.00000561637137, 742.0000120805139, 741.99997950730904, 742.00001639877985, 741.99998661823088, 741.99998409807711, 741.99997965483453, 742.0000025934761, 741.99999377298991, 741.99996630206169, 741.99999279699693, 742.00000538150448, 741.9999992525311, 742.00000070992974, 742.00000728451153, 742.00002910774731, 742.0000336289886, 742.00000747806314, 741.99998355787511, 742.0000173552321, 741.99999576717562, 741.99998989357528, 741.99999101652145, 742.00001168296023, 742.00001374594672, 741.99996823128777, 742.00000210860048, 741.99999638610302, 741.99997651760509, 742.00000676493755, 741.99998561739574, 741.9999953119974, 741.99999688992136, 741.99998986982598]\n",
      "observed srat: 741.999976503\n",
      "p(LRT) = 0.09\n",
      "KSP(obs) = 0.685345233619\n",
      "mean(sim_ksp) = 0.644799522101\n",
      "Merit(obs) = 359.736373665\n",
      "mean(sim_merit) = 367.518531815\n",
      "Srat(obs) = 741.999976503\n",
      "mean(sim_srat) = 741.999997084\n",
      "Bayesian p-value for maximum power P_max =  0.33 +/- 0.047021271782\n",
      "Bayesian p-value for deviance D =  0.48 +/- 0.0499599839872\n",
      "Bayesian p-value for KS test: 0.5 +/- 0.05\n",
      "Bayesian p-value for Merit function: 0.62 +/- 0.048538644398\n",
      "Bayesian p-value for the np.sum of residuals: 0.93 +/- 0.0255147016443\n",
      "Bayesian p-value for Likelihood Ratio: 0.09 +/- 0.0286181760425\n"
     ]
    }
   ],
   "source": [
    "## the two noise models\n",
    "model1 = pl\n",
    "model2 = bpl\n",
    "\n",
    "## input parameters for both\n",
    "par1 = [1.,4.,np.log(2.0)]\n",
    "par2 = [1.,3.,2.,3., np.log(2.0)]\n",
    "\n",
    "## parameters for the MCMC run\n",
    "nchain = 200 ## number of emcee walkers\n",
    "niter = 200 ## number of iterations per chain\n",
    "nsim = 100 ## number of simulations to run\n",
    "\n",
    "psfit, fakeper, summary = bb.choose_noise_model(model1, par1,\n",
    "                                               model2, par2, \n",
    "                                               fitmethod=\"bfgs\",\n",
    "                                               nchain = nchain, niter = niter,\n",
    "                                               nsim = nsim, writefile=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Running this code will print a lot of diagnostics on the screen (and also to a log file): the results of the MAP fitting for both models, mean, standard deviations and quantiles for the three parameters and more.\n",
    "\n",
    "It also returns a bunch of objects useful for further analysis:\n",
    "* `psfit` contains a `PerMaxLike` object. In its attributes `plfit` and `bplfit` it contains summary dictionaries for the power law and bent power law models, respectively, with results from the initial MAP fit on the data, as we've created when we did the fitting by hand above\n",
    "* `fakeper` contains the list of all fake periodograms created during the simulation stage\n",
    "* `summary` is a dictionary with the results printed at the very end of the analysis.\n",
    "\n",
    "You should also have a couple of plots, all starting with whatever string you gave it for variable `namestr` above (in my case \"demo\"):\n",
    "* `demo_ps_fit.png` shows the periodogram and the MAP fits for the two broadband noise models\n",
    "* `demo_scatter.png` shows a triangle plot of the posterior distributions of the parameters for model 1. This can quite useful for diagnosing how well behaved the posterior distribution is, and whether there are correlations between parameters\n",
    "* `demo_quantiles.png` shows the 80% quantiles for all parameters and all Markov chains/walkers. This plot is more useful for Metropolis-Hastings than it is for emcee.\n",
    "* `demo_rhat.png` plots $\\hat{R}$ for all parameters in model 1. $\\hat{R}$ is another quantity for diagnosing convergence. It compares the variance within Markov chains to the variance between Markov chains. In general, well-mixed chains will have $\\hat{R} \\approx 1$. If it's much larger than 1.2, I'd start worrying a bit (and perhaps either increase the number of chains (in emcee) or the number of samples (in both MH and emcee). \n",
    "* `demo_lrt.png` shows a histogram of the posterior distribution of the likelihood ratios constructed from model 1, together with the observed value.\n",
    "\n",
    "\n",
    "In the very end, the code will print to the screen a bunch of posterior predictive p-values; the most important one here is the one for the likelihood ratio. What we've done in this part of the analysis is essentially this:\n",
    "1. compute MAP estimates for both models chosen to compare for the data\n",
    "2. compute the likelihood ratio of both models for the data\n",
    "3. pick parameter sets from the posterior PDF for model 1 via MCMC\n",
    "4. from `nsim` randomly picked parameter sets, simulate a periodogram for each\n",
    "5. fit all `nsim` fake periodograms with both models, compute the likelihood ratio for each\n",
    "6. build a posterior distribution for the likelihood ratio of both models under the null hypothesis that model 1 is actually representative of the data\n",
    "7. compute how many samples in the distribution lie above the value computed for the data and divide by the total number of samples for the p-value.\n",
    "\n",
    "This number essentially tells you what likelihood ratio would be expected if the data were generated from model 1. \n",
    "If the observed likelihood ratio is an outlier with respect to the derived distribution, this could be taken as an indicator that the data are unlikely to be generated. However, it is explicitly **not** an indicator that the data were instead generated from model 2. Strictly speaking, this conclusion is not supported by the test we've done, although we will use it in a way that might seem to imply it. \n",
    "There could be other reasons for why the likelihood ratio we have observed is an outlier with respect to the distributions derived from the posterior sample: we could have simply picked two models that don't particularly describe the data very well, so that neither is an appropriate model for the data. Or perhaps our statistical distributions aren't quite what we expected them to be (which can be the case for dead time), which can also have an effect. \n",
    "\n",
    "In conclusion, be wary of any results you derive from the analysis above. Model comparison is always tricky, but for QPO detection, having a model that is a reasonable approximation of the broadband shape of the periodogram is good enough. So you can rightfully skip this step and just use the more complex model (usually a bent power law) and get away with it.\n",
    "\n",
    "Now that we've got that out of the way, let's do the actual QPO fitting. There's a method for that, too!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient and/or function calls not changing!\n",
      "Approximating covariance from BFGS: \n",
      "Covariance (empirical): [[ 0.38054755  0.23509512  0.68112036  1.2383846  -0.01812769]\n",
      " [ 0.23509512  0.31074405  0.23346897  0.53388234 -0.02790734]\n",
      " [ 0.68112036  0.23346897  1.52872923  2.53538571 -0.00838119]\n",
      " [ 1.2383846   0.53388234  2.53538571  4.39645654 -0.03488924]\n",
      " [-0.01812769 -0.02790734 -0.00838119 -0.03488924  0.00595677]]\n",
      "The best-fit model parameters plus errors are:\n",
      "Parameter 0: 1.18492034413 +/- 0.6168853646\n",
      "Parameter 1: 9.05996213796 +/- 0.557444211711\n",
      "Parameter 2: 2.87967378908 +/- 1.23641790086\n",
      "Parameter 3: 3.32810167723 +/- 2.09677288761\n",
      "Parameter 4: 0.610094126788 +/- 0.077180137587\n",
      "The Akaike Information Criterion of the power law model is: 888.151939903.\n",
      "The figure-of-merit function for this model is: 358.350560945 and the fit for 366.0 dof is 0.979099893291.\n",
      "Fitting statistics: \n",
      " -- number of frequencies: 371\n",
      " -- Deviance [-2 log L] D = 1756.30387981\n",
      " -- Highest data/model outlier 2I/S = 14.5414216556\n",
      "    at frequency f_max = 187.499999999\n",
      " -- Highest smoothed data/model outlier for smoothing factor [3] 2I/S = 7.03906642037\n",
      "    at frequency f_max = 452.284946234\n",
      " -- Highest smoothed data/model outlier for smoothing factor [5] 2I/S = 5.53651404424\n",
      "    at frequency f_max = 450.940860213\n",
      " -- Highest smoothed data/model outlier for smoothing factor [11] 2I/S = 5.03531944576\n",
      "    at frequency f_max = 8.73655913974\n",
      " -- Summed Residuals S = 741.999930018\n",
      " -- Expected S ~ 3710.0 +- 86.1394218694\n",
      " -- KS test p-value (use with caution!) p = 0.518561094036\n",
      " -- merit function (SSE) M = 358.350560945\n",
      "<--- self.ps len MCMC: 372\n",
      "mcobs topt: [ 1.18492034  9.05996214  2.87967379  3.32810168  0.61009413]\n",
      "mcobs tcov: [[ 0.38054755  0.23509512  0.68112036  1.2383846  -0.01812769]\n",
      " [ 0.23509512  0.31074405  0.23346897  0.53388234 -0.02790734]\n",
      " [ 0.68112036  0.23346897  1.52872923  2.53538571 -0.00838119]\n",
      " [ 1.2383846   0.53388234  2.53538571  4.39645654 -0.03488924]\n",
      " [-0.01812769 -0.02790734 -0.00838119 -0.03488924  0.00595677]]\n",
      "The ensemble acceptance rate is: 0.28495\n",
      "The autocorrelation times are: [ 92.33495397  92.80701972  90.84735406  90.30316705  87.92865471]\n",
      "Computing Rhat. The closer to 1, the better!\n",
      "The Rhat value for parameter 0 is: 1.46023851192.\n",
      "*** HIGH Rhat! Check results! ***\n",
      "The Rhat value for parameter 1 is: 1.34357863235.\n",
      "*** HIGH Rhat! Check results! ***\n",
      "The Rhat value for parameter 2 is: 1.37454585792.\n",
      "*** HIGH Rhat! Check results! ***\n",
      "The Rhat value for parameter 3 is: 1.32464426223.\n",
      "*** HIGH Rhat! Check results! ***\n",
      "The Rhat value for parameter 4 is: 1.17739333246.\n",
      "Good Rhat. Hoorah!\n",
      "I am on parameter: 0\n",
      "I am on parameter: 1\n",
      "I am on parameter: 2\n",
      "I am on parameter: 3\n",
      "I am on parameter: 4\n",
      "Covariance matrix (after simulations): \n",
      "\n",
      "[[  3.91373364e-01   7.13646746e-01   4.77388511e-02   7.32938872e-01\n",
      "   -3.24616626e-05]\n",
      " [  7.13646746e-01   2.28099929e+00  -5.37695684e-01   4.30752924e-01\n",
      "   -2.62363003e-02]\n",
      " [  4.77388511e-02  -5.37695684e-01   1.82864894e+00   1.98427711e+00\n",
      "    4.49952231e-02]\n",
      " [  7.32938872e-01   4.30752924e-01   1.98427711e+00   9.40556307e+00\n",
      "   -5.19618599e-02]\n",
      " [ -3.24616626e-05  -2.62363003e-02   4.49952231e-02  -5.19618599e-02\n",
      "    1.60562458e-02]]\n",
      "-- Posterior Summary of Parameters: \n",
      "\n",
      "parameter \t mean \t\t sd \t\t 5% \t\t 95% \n",
      "\n",
      "---------------------------------------------\n",
      "\n",
      "theta[0] \t 1.57332426574\t0.625596841002\t0.564779377173\t2.58817910952\n",
      "\n",
      "theta[1] \t 10.4658628836\t1.51029397423\t8.8520366472\t13.6129575524\n",
      "\n",
      "theta[2] \t 3.06267798509\t1.35227208641\t1.25704957652\t5.95116155143\n",
      "\n",
      "theta[3] \t 3.98719443967\t3.06684137851\t0.672488238187\t9.25536643647\n",
      "\n",
      "theta[4] \t 0.561728484633\t0.126712925624\t0.335462828362\t0.74798418577\n",
      "\n",
      "N: 5\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "ninetyfiveperlim: 950\n",
      "The posterior p-value for the maximum residual power for a binning of 1.3440860215Hz is p = 0.187 +/- 0.0123300851579\n",
      "The corresponding value of the T_R statistic at frequency f = 187.499999999 is 2I/S = 14.5414216556\n",
      "The upper limit on the T_R statistic is 2I/S = 17.3924581565\n",
      "bintemplate[0]: 13755.7601905\n",
      "The upper limit on the power at 40.0Hz for a binning of 1 is P = 314.469612646\n",
      "The upper limit on the rms amplitude at 40.0Hz for a binning of 1 is rms = 0.155531251533\n",
      "The upper limit on the power at 70.0Hz for a binning of 1 is P = 91.2493711544\n",
      "The upper limit on the rms amplitude at 70.0Hz for a binning of 1 is rms = 0.0837805609703\n",
      "The upper limit on the power at 100.0Hz for a binning of 1 is P = 44.2444642037\n",
      "The upper limit on the rms amplitude at 100.0Hz for a binning of 1 is rms = 0.0583388406069\n",
      "The upper limit on the power at 300.0Hz for a binning of 1 is P = 15.5253802421\n",
      "The upper limit on the rms amplitude at 300.0Hz for a binning of 1 is rms = 0.034558067345\n",
      "The upper limit on the power at 500.0Hz for a binning of 1 is P = 14.4796207062\n",
      "The upper limit on the rms amplitude at 500.0Hz for a binning of 1 is rms = 0.0333738966469\n",
      "The upper limit on the power at 1000.0Hz for a binning of 1 is P = 14.4796207062\n",
      "The upper limit on the rms amplitude at 1000.0Hz for a binning of 1 is rms = 0.0333738966469\n",
      "ninetyfiveperlim: 950\n",
      "The posterior p-value for the maximum residual power for a binning of 4.0322580645Hz is p = 0.289 +/- 0.014334538709\n",
      "The corresponding value of the T_R statistic at frequency f = [ 448.25268817] is 2I/S = 6.4078037666\n",
      "The upper limit on the T_R statistic is 2I/S = 7.79295826641\n",
      "bintemplate[0]: 13755.7601905\n",
      "The upper limit on the power at 40.0Hz for a binning of 3 is P = 137.732080062\n",
      "The upper limit on the rms amplitude at 40.0Hz for a binning of 3 is rms = 0.102930925331\n",
      "The upper limit on the power at 70.0Hz for a binning of 3 is P = 34.3417401925\n",
      "The upper limit on the rms amplitude at 70.0Hz for a binning of 3 is rms = 0.0513972015045\n",
      "The upper limit on the power at 100.0Hz for a binning of 3 is P = 17.0779593137\n",
      "The upper limit on the rms amplitude at 100.0Hz for a binning of 3 is rms = 0.036244850365\n",
      "The upper limit on the power at 300.0Hz for a binning of 3 is P = 5.84298355066\n",
      "The upper limit on the rms amplitude at 300.0Hz for a binning of 3 is rms = 0.0212004781344\n",
      "The upper limit on the power at 500.0Hz for a binning of 3 is P = 5.45125405587\n",
      "The upper limit on the rms amplitude at 500.0Hz for a binning of 3 is rms = 0.02047748117\n",
      "The upper limit on the power at 1000.0Hz for a binning of 3 is P = 5.44850449016\n",
      "The upper limit on the rms amplitude at 1000.0Hz for a binning of 3 is rms = 0.0204723161858\n",
      "ninetyfiveperlim: 950\n",
      "The posterior p-value for the maximum residual power for a binning of 6.72043010749Hz is p = 0.141 +/- 0.0110054077616\n",
      "The corresponding value of the T_R statistic at frequency f = [ 450.94086021] is 2I/S = 5.25321775542\n",
      "The upper limit on the T_R statistic is 2I/S = 5.91817072144\n",
      "bintemplate[0]: 13755.7601905\n",
      "The upper limit on the power at 40.0Hz for a binning of 5 is P = 109.380587815\n",
      "The upper limit on the rms amplitude at 40.0Hz for a binning of 5 is rms = 0.0917272662321\n",
      "The upper limit on the power at 70.0Hz for a binning of 5 is P = 24.2444648619\n",
      "The upper limit on the rms amplitude at 70.0Hz for a binning of 5 is rms = 0.0431851691618\n",
      "The upper limit on the power at 100.0Hz for a binning of 5 is P = 12.1729321139\n",
      "The upper limit on the rms amplitude at 100.0Hz for a binning of 5 is rms = 0.0306003168836\n",
      "The upper limit on the power at 300.0Hz for a binning of 5 is P = 3.96102706255\n",
      "The upper limit on the rms amplitude at 300.0Hz for a binning of 5 is rms = 0.0174554973984\n",
      "The upper limit on the power at 500.0Hz for a binning of 5 is P = 3.68642661071\n",
      "The upper limit on the rms amplitude at 500.0Hz for a binning of 5 is rms = 0.0168395747496\n",
      "The upper limit on the power at 1000.0Hz for a binning of 5 is P = 3.68642661071\n",
      "The upper limit on the rms amplitude at 1000.0Hz for a binning of 5 is rms = 0.0168395747496\n",
      "ninetyfiveperlim: 950\n",
      "The posterior p-value for the maximum residual power for a binning of 9.40860215049Hz is p = 0.522 +/- 0.015796075462\n",
      "The corresponding value of the T_R statistic at frequency f = [ 320.56451613] is 2I/S = 3.81963906421\n",
      "The upper limit on the T_R statistic is 2I/S = 4.91599987352\n",
      "bintemplate[0]: 13755.7601905\n",
      "The upper limit on the power at 40.0Hz for a binning of 7 is P = 64.1991417834\n",
      "The upper limit on the rms amplitude at 40.0Hz for a binning of 7 is rms = 0.070273718571\n",
      "The upper limit on the power at 70.0Hz for a binning of 7 is P = 18.8528898242\n",
      "The upper limit on the rms amplitude at 70.0Hz for a binning of 7 is rms = 0.0380817842829\n",
      "The upper limit on the power at 100.0Hz for a binning of 7 is P = 9.05939812942\n",
      "The upper limit on the rms amplitude at 100.0Hz for a binning of 7 is rms = 0.0263984238012\n",
      "The upper limit on the power at 300.0Hz for a binning of 7 is P = 2.95841342622\n",
      "The upper limit on the rms amplitude at 300.0Hz for a binning of 7 is rms = 0.0150854321634\n",
      "The upper limit on the power at 500.0Hz for a binning of 7 is P = 2.74306882751\n",
      "The upper limit on the rms amplitude at 500.0Hz for a binning of 7 is rms = 0.0145260212868\n",
      "The upper limit on the power at 1000.0Hz for a binning of 7 is P = 2.74306882751\n",
      "The upper limit on the rms amplitude at 1000.0Hz for a binning of 7 is rms = 0.0145260212868\n",
      "ninetyfiveperlim: 950\n",
      "The posterior p-value for the maximum residual power for a binning of 13.440860215Hz is p = 0.191 +/- 0.0124305671632\n",
      "The corresponding value of the T_R statistic at frequency f = [ 444.22043011] is 2I/S = 3.72017926193\n",
      "The upper limit on the T_R statistic is 2I/S = 4.19479265998\n",
      "bintemplate[0]: 13755.7601905\n",
      "The upper limit on the power at 40.0Hz for a binning of 10 is P = 95.7556596671\n",
      "The upper limit on the rms amplitude at 40.0Hz for a binning of 10 is rms = 0.0858243553683\n",
      "The upper limit on the power at 70.0Hz for a binning of 10 is P = 13.5807184799\n",
      "The upper limit on the rms amplitude at 70.0Hz for a binning of 10 is rms = 0.0323213652605\n",
      "The upper limit on the power at 100.0Hz for a binning of 10 is P = 6.8187590469\n",
      "The upper limit on the rms amplitude at 100.0Hz for a binning of 10 is rms = 0.0229024000202\n",
      "The upper limit on the power at 300.0Hz for a binning of 10 is P = 2.21879896027\n",
      "The upper limit on the rms amplitude at 300.0Hz for a binning of 10 is rms = 0.0130643347744\n",
      "The upper limit on the power at 500.0Hz for a binning of 10 is P = 2.06497946158\n",
      "The upper limit on the rms amplitude at 500.0Hz for a binning of 10 is rms = 0.012603355663\n",
      "The upper limit on the power at 1000.0Hz for a binning of 10 is P = 2.06497946158\n",
      "The upper limit on the rms amplitude at 1000.0Hz for a binning of 10 is rms = 0.012603355663\n",
      "ninetyfiveperlim: 950\n",
      "The posterior p-value for the maximum residual power for a binning of 20.1612903225Hz is p = 0.135 +/- 0.0108062481926\n",
      "The corresponding value of the T_R statistic at frequency f = [ 242.60752688] is 2I/S = 3.30174077612\n",
      "The upper limit on the T_R statistic is 2I/S = 3.54701120068\n",
      "bintemplate[0]: 13755.7601905\n",
      "The upper limit on the power at 40.0Hz for a binning of 15 is P = 114.578501219\n",
      "The upper limit on the rms amplitude at 40.0Hz for a binning of 15 is rms = 0.0938814724161\n",
      "The upper limit on the power at 70.0Hz for a binning of 15 is P = 12.0535134415\n",
      "The upper limit on the rms amplitude at 70.0Hz for a binning of 15 is rms = 0.0304498496163\n",
      "The upper limit on the power at 100.0Hz for a binning of 15 is P = 6.51020595864\n",
      "The upper limit on the rms amplitude at 100.0Hz for a binning of 15 is rms = 0.022378227672\n",
      "The upper limit on the power at 300.0Hz for a binning of 15 is P = 1.58374775975\n",
      "The upper limit on the rms amplitude at 300.0Hz for a binning of 15 is rms = 0.0110375156059\n",
      "The upper limit on the power at 500.0Hz for a binning of 15 is P = 1.45810586562\n",
      "The upper limit on the rms amplitude at 500.0Hz for a binning of 15 is rms = 0.0105906557711\n",
      "The upper limit on the power at 1000.0Hz for a binning of 15 is P = 1.45810586562\n",
      "The upper limit on the rms amplitude at 1000.0Hz for a binning of 15 is rms = 0.0105906557711\n",
      "ninetyfiveperlim: 950\n",
      "The posterior p-value for the maximum residual power for a binning of 26.88172043Hz is p = 0.065 +/- 0.00779583221985\n",
      "The corresponding value of the T_R statistic at frequency f = [ 323.25268817] is 2I/S = 3.18607853041\n",
      "The upper limit on the T_R statistic is 2I/S = 3.22837152332\n",
      "bintemplate[0]: 13755.7601905\n",
      "The upper limit on the power at 40.0Hz for a binning of 20 is P = 53.5920898936\n",
      "The upper limit on the rms amplitude at 40.0Hz for a binning of 20 is rms = 0.0642064518047\n",
      "The upper limit on the power at 70.0Hz for a binning of 20 is P = 12.4177370852\n",
      "The upper limit on the rms amplitude at 70.0Hz for a binning of 20 is rms = 0.0309064806314\n",
      "The upper limit on the power at 100.0Hz for a binning of 20 is P = 5.16929134517\n",
      "The upper limit on the rms amplitude at 100.0Hz for a binning of 20 is rms = 0.0199408574485\n",
      "The upper limit on the power at 300.0Hz for a binning of 20 is P = 1.24180725973\n",
      "The upper limit on the rms amplitude at 300.0Hz for a binning of 20 is rms = 0.00977361935843\n",
      "The upper limit on the power at 500.0Hz for a binning of 20 is P = 1.15777812244\n",
      "The upper limit on the rms amplitude at 500.0Hz for a binning of 20 is rms = 0.00943715293783\n",
      "The upper limit on the power at 1000.0Hz for a binning of 20 is P = 1.15777812244\n",
      "The upper limit on the rms amplitude at 1000.0Hz for a binning of 20 is rms = 0.00943715293783\n",
      "ninetyfiveperlim: 950\n",
      "The posterior p-value for the maximum residual power for a binning of 40.322580645Hz is p = 0.523 +/- 0.0157946509933\n",
      "The corresponding value of the T_R statistic at frequency f = [ 323.25268817] is 2I/S = 2.43708994441\n",
      "The upper limit on the T_R statistic is 2I/S = 2.8567870583\n",
      "bintemplate[0]: 13755.7601905\n",
      "The upper limit on the power at 70.0Hz for a binning of 30 is P = 16.2763217795\n",
      "The upper limit on the rms amplitude at 70.0Hz for a binning of 30 is rms = 0.0353839617944\n",
      "The upper limit on the power at 100.0Hz for a binning of 30 is P = 3.60557196339\n",
      "The upper limit on the rms amplitude at 100.0Hz for a binning of 30 is rms = 0.0166538791124\n",
      "The upper limit on the power at 300.0Hz for a binning of 30 is P = 0.877133005607\n",
      "The upper limit on the rms amplitude at 300.0Hz for a binning of 30 is rms = 0.00821412013925\n",
      "The upper limit on the power at 500.0Hz for a binning of 30 is P = 0.807548280672\n",
      "The upper limit on the rms amplitude at 500.0Hz for a binning of 30 is rms = 0.00788156700874\n",
      "The upper limit on the power at 1000.0Hz for a binning of 30 is P = 0.807548280672\n",
      "The upper limit on the rms amplitude at 1000.0Hz for a binning of 30 is rms = 0.00788156700874\n",
      "ninetyfiveperlim: 950\n",
      "The posterior p-value for the maximum residual power for a binning of 67.2043010749Hz is p = 0.701 +/- 0.0144775343205\n",
      "The corresponding value of the T_R statistic at frequency f = [ 403.89784946] is 2I/S = 2.13099691433\n",
      "The upper limit on the T_R statistic is 2I/S = 2.50454522865\n",
      "bintemplate[0]: 13755.7601905\n",
      "The upper limit on the power at 70.0Hz for a binning of 50 is P = 3.12197449699\n",
      "The upper limit on the rms amplitude at 70.0Hz for a binning of 50 is rms = 0.0154968346569\n",
      "The upper limit on the power at 100.0Hz for a binning of 50 is P = 3.12197449699\n",
      "The upper limit on the rms amplitude at 100.0Hz for a binning of 50 is rms = 0.0154968346569\n",
      "The upper limit on the power at 300.0Hz for a binning of 50 is P = 0.524279586098\n",
      "The upper limit on the rms amplitude at 300.0Hz for a binning of 50 is rms = 0.00635052745295\n",
      "The upper limit on the power at 500.0Hz for a binning of 50 is P = 0.476491161859\n",
      "The upper limit on the rms amplitude at 500.0Hz for a binning of 50 is rms = 0.00605418584922\n",
      "The upper limit on the power at 1000.0Hz for a binning of 50 is P = 0.476491161859\n",
      "The upper limit on the rms amplitude at 1000.0Hz for a binning of 50 is rms = 0.00605418584922\n",
      "ninetyfiveperlim: 950\n",
      "The posterior p-value for the maximum residual power for a binning of 94.0860215049Hz is p = 0.488 +/- 0.0158068339651\n",
      "The corresponding value of the T_R statistic at frequency f = [ 282.93010753] is 2I/S = 2.08277193773\n",
      "The upper limit on the T_R statistic is 2I/S = 2.32064661049\n",
      "bintemplate[0]: 13755.7601905\n",
      "The upper limit on the power at 100.0Hz for a binning of 70 is P = 0.996181560093\n",
      "The upper limit on the rms amplitude at 100.0Hz for a binning of 70 is rms = 0.00875381921086\n",
      "The upper limit on the power at 300.0Hz for a binning of 70 is P = 0.328260940066\n",
      "The upper limit on the rms amplitude at 300.0Hz for a binning of 70 is rms = 0.00502502154657\n",
      "The upper limit on the power at 500.0Hz for a binning of 70 is P = 0.302817799676\n",
      "The upper limit on the rms amplitude at 500.0Hz for a binning of 70 is rms = 0.00482635233879\n",
      "The upper limit on the power at 1000.0Hz for a binning of 70 is P = 0.302817799676\n",
      "The upper limit on the rms amplitude at 1000.0Hz for a binning of 70 is rms = 0.00482635233879\n",
      "ninetyfiveperlim: 950\n",
      "The posterior p-value for the maximum residual power for a binning of 134.40860215Hz is p = 0.625 +/- 0.0153093108924\n",
      "The corresponding value of the T_R statistic at frequency f = [ 269.48924731] is 2I/S = 1.84428180035\n",
      "The upper limit on the T_R statistic is 2I/S = 2.15428689672\n",
      "bintemplate[0]: 13755.7601905\n",
      "The upper limit on the power at 300.0Hz for a binning of 100 is P = 0.160321544556\n",
      "The upper limit on the rms amplitude at 300.0Hz for a binning of 100 is rms = 0.00351175547331\n",
      "The upper limit on the power at 500.0Hz for a binning of 100 is P = 0.147767277518\n",
      "The upper limit on the rms amplitude at 500.0Hz for a binning of 100 is rms = 0.00337145571753\n",
      "The upper limit on the power at 1000.0Hz for a binning of 100 is P = 0.147767277518\n",
      "The upper limit on the rms amplitude at 1000.0Hz for a binning of 100 is rms = 0.00337145571753\n",
      "Bayesian p-value for maximum power P_max =  0.187 +/- 0.0123300851579\n",
      "Bayesian p-value for maximum power P_max =  0.431 +/- 0.0156601085565\n",
      "Bayesian p-value for maximum power P_max =  0.545 +/- 0.0157472219772\n",
      "Bayesian p-value for maximum power P_max =  0.497 +/- 0.0158111036933\n",
      "Bayesian p-value for deviance D =  0.497 +/- 0.0158111036933\n",
      "Bayesian p-value for KS test: 0.692 +/- 0.0145991780591\n",
      "Bayesian p-value for Merit function: 0.496 +/- 0.0158108823283\n",
      "Bayesian p-value for the np.sum of residuals: 0.854 +/- 0.0111661989952\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAesAAAFeCAYAAACl9DdnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11204add0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "noise_model = bpl\n",
    "par = [1,3,2,3,np.log(2.0)]\n",
    "nchain = 200\n",
    "niter = 1000\n",
    "nsim = 1000\n",
    "\n",
    "results = bb.find_periodicity(noise_model, par, \n",
    "                             nchain=nchain, niter=niter, nsim=nsim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much like the `choose_noise_model` method above, this code prints a bunch of useful information to the screen (and a log file) and makes some figures. \n",
    "\n",
    "Most importantly, it prints a bunch of blocks that start with \"The posterior p-value for the maximum residual power [...]\". Each of these blocks details the results for the binned periodogram at the specified frequency. \n",
    "The rationale behind this is that QPOs can be narrow or broad: a single QPO might be spread out over several frequency bins, or it might be so coherent it is mostly concentrated in one bin (although even then, sampling will usually cause it to be spread over two adjacent bins). So in searching for QPOs in various frequency bins, we do not risk missing signals that may be broader than the native frequency resolution. \n",
    "Of course, the fact that we've searched more than one periodgram needs to be taken into account when computing the number of trials: while strictly speaking, the binned periodograms are not statistically independent of each other, the conservative assumption to make is that they are, and multiply the number of trials by 7 (the number of frequency bins searched).\n",
    "\n",
    "Note that after that initial statement, which includes the frequency bin width as well as the posterior p-value (uncorrected for the number of trials in general, including the frequency *binning*, but it does take into account the fact that we searched many frequencies per periodogram), it also prints $T_{R,j} = \\max_j{2I_j/S_j}$, where $I_j$ is the power at frequency $j$ and $S_j$ is the model power spectrum at frequency $j$. \n",
    "Finally, it also prints the upper limit (actually, strictly speaking we show the sensitivity) the fractional rms amplitude that we could have detected at a few useful frequencies. Note that this sensitivity depends on *frequency*, because the broadband noise depends on frequency and changes the sensitivity at various frequencies. \n",
    "\n",
    "Again, this method produces two different plots:\n",
    "* `demo_scatter.png`, which is the same plot as produced during the model comparison step, but for whatever model was used for finding QPOs\n",
    "* `demo_maxpow.png` shows the posterior distribution for four different frequency bins. Actually, what it shows are the data at the native time resolution as well as for three different Wiener filter smoothed periodograms (which I thought might be useful at some point, but don't really use in practice). \n",
    "\n",
    "Usually, when searching for QPOs, I will do the search with `nsim=1000` and derive p-values up to $10^{-3}$ to conserve computation. Then I will pick all light curves that have a p-value (corrected for number of trials) of $<10^{-2}$ in at least two or more frequency bins, and re-run those with however many simulations are required to be confident the detection is real.\n",
    "For example, if I had 250 bursts, each of which I decided to run once (for the full light curve), and decided that I'll report any signal that has a posterior predictive p-value, corrected for the number of trials, of $10^{-2}$, then I would have to re-run those bursts that have candidate signals with at least $\\frac{10^{-2}}{250 \\times 7 \\times 100}$ simulations, $250$ for the number of bursts, $7$ for the number of frequency bins, and then another factor of $100$ to make sure I have enough simulations to actually trace out the tail of the distribution sufficiently. This can be a very large number, in which case memory can become an issue. If it does, move to a bigger computer, or let me know!\n",
    "\n",
    "\n",
    "# Running Several Bursts at Once\n",
    "\n",
    "The code above will work well for the occasional burst, but for large data sets, you'd want to automate it. Of course, you could do that yourself, but for various useful corner cases, there's some code set up that will make things simple.\n",
    "\n",
    "Especially for *Fermi*/GBM data, the following code will be useful. \n",
    "Below will be two cases:\n",
    "1. Data that comes out of my *Fermi*/GBM processing pipeline\n",
    "2. Data that is stored in an ascii text file (the file format either needs to match the one below, or you'll need to change the code to something that matches your file name structure). \n",
    "\n",
    "At the heart of this is a set of classes called `Burst` and `GBMBurst` that define useful methods for bursts (and can easily be extended). In particular, class `Burst` has a method that runs the Bayesian QPO search automatically.\n",
    "\n",
    "What you're going to need for the following analysis are\n",
    "1. the data files with the TTE data; this must contain in the first column photon arrival times, in the second (optionally) photon energies or channels\n",
    "2. a file that has at least three columns:\n",
    "    * the identifier for the observations (e.g. the *Fermi*/GBM trigger ID)\n",
    "    * the burst start times in the same format as the TTE photon arrival times (seconds since trigger works pretty well)\n",
    "    * the burst duration in seconds \n",
    "\n",
    "## Using the Burst class to simplify things\n",
    "\n",
    "For a single light curve, like the one used above, we can make a `GBMBurst` object as done below. When creating this object, it will automatically create a light curve and periodogram up to whatever Nyquist frequency is specified. It is also possible to specify the normalization of the periodogram, the fluence of the burst and the peak energy for various purposes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['090122283', '+071.87300', 'eventfile.dat']\n",
      "length time: 1185\n",
      "tseg: 0.1198999881\n",
      "length lc: 1146\n"
     ]
    }
   ],
   "source": [
    "from BayesPSD import GBMBurst\n",
    "\n",
    "## load data\n",
    "data = np.loadtxt('../data/090122283_+071.87300_eventfile.dat')\n",
    "times = data[:,0] ## photon arrival times\n",
    "events = data[:,1] ## photon energies\n",
    "\n",
    "## we can get ObsID and start time from the file name in this case\n",
    "## for others, we might need to read it from a file\n",
    "\n",
    "#split filename into components and get ObsID and start time\n",
    "fsplit = \"090122283_+071.87300_eventfile.dat\".split(\"_\")\n",
    "print(fsplit)\n",
    "bid = fsplit[0] ##ObsID\n",
    "bst = np.float(fsplit[1]) ## burst start time\n",
    "\n",
    "## let's pretend we know the burst duration\n",
    "blen = 0.1\n",
    "\n",
    "## we're going to search between 8 and 200 keV\n",
    "energies = [8.0, 200.0]\n",
    "\n",
    "## We want to search up to 4096 Hz:\n",
    "fnyquist = 4096.\n",
    "\n",
    "\n",
    "## create GBMBurst object; note the confusing syntax:\n",
    "## - energies contains energy ranges to use\n",
    "## - events actually contains the list of photon energies\n",
    "burst = GBMBurst(bid=bid, bstart=bst, blength=blen,\n",
    "                energies=energies, photons=times, events=events, \n",
    "                instrument=\"gbm\", fnyquist=fnyquist)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that for convenience, the code adds 20% of the burst duration on either side of the light curve, to make sure the light curve goes back to the background on either side (anything can cause funny effects in the Fourier transform!). \n",
    "\n",
    "We can now look at the light curve:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1177f92d0>]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeUAAAFVCAYAAADR+vcXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1178bbc10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lc = burst.lc\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(lc.time, lc.counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or the periodogram:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1140ce810>]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe8AAAFdCAYAAAAqi+WzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ndQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1138cadd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ps = burst.ps\n",
    "\n",
    "plt.figure()\n",
    "plt.loglog(ps.freq[1:], ps.ps[1:], lw=2, linestyle=\"steps-mid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or we can run the entire Bayesian QPO search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient and/or function calls not changing!\n",
      "Approximating covariance from BFGS: \n",
      "Covariance (empirical): [[  3.3041113   11.58464322   0.91335737]\n",
      " [ 11.58464322  40.64444461   3.20574894]\n",
      " [  0.91335737   3.20574894   0.25350497]]\n",
      "The best-fit model parameters plus errors are:\n",
      "Parameter 0: 2.01701268072 +/- 1.81772145786\n",
      "Parameter 1: 10.9124276295 +/- 6.37529957047\n",
      "Parameter 2: 0.661178594119 +/- 0.503492770119\n",
      "The Akaike Information Criterion of the power law model is: 1017.82052436.\n",
      "The figure-of-merit function for this model is: 507.885862742 and the fit for 569.0 dof is 0.892593783377.\n",
      "Fitting statistics: \n",
      " -- number of frequencies: 572\n",
      " -- Deviance [-2 log L] D = 2023.64104872\n",
      " -- Highest data/model outlier 2I/S = 9.25528143066\n",
      "    at frequency f_max = 3220.32809773\n",
      " -- Highest smoothed data/model outlier for smoothing factor [3] 2I/S = 6.81329383064\n",
      "    at frequency f_max = 4006.64572426\n",
      " -- Highest smoothed data/model outlier for smoothing factor [5] 2I/S = 5.44365614092\n",
      "    at frequency f_max = 3999.4973822\n",
      " -- Highest smoothed data/model outlier for smoothing factor [11] 2I/S = 5.68352241407\n",
      "    at frequency f_max = 75.057591623\n",
      " -- Summed Residuals S = 1143.99996136\n",
      " -- Expected S ~ 3432.0 +- 82.8492607088\n",
      " -- KS test p-value (use with caution!) p = 0.786363221389\n",
      " -- merit function (SSE) M = 507.885862742\n",
      "Approximating covariance from BFGS: \n",
      "Covariance (empirical): [[  9.47715378e+00   2.33068919e+01   5.36412536e-01   7.48605475e-01\n",
      "    1.50760338e-02]\n",
      " [  2.33068919e+01   5.82320509e+01   1.24207292e+00   1.68198904e+00\n",
      "    3.50361023e-02]\n",
      " [  5.36412536e-01   1.24207292e+00   2.25962360e-01   9.39538461e-02\n",
      "    7.42350379e-03]\n",
      " [  7.48605475e-01   1.68198904e+00   9.39538461e-02   9.62935852e-02\n",
      "    2.62055890e-03]\n",
      " [  1.50760338e-02   3.50361023e-02   7.42350379e-03   2.62055890e-03\n",
      "    2.10872372e-03]]\n",
      "The best-fit model parameters plus errors are:\n",
      "Parameter 0: -4.35539979451 +/- 3.07849862402\n",
      "Parameter 1: -7.00010902689 +/- 7.63099278745\n",
      "Parameter 2: 2.3253433496 +/- 0.475354983359\n",
      "Parameter 3: 2.89251618296 +/- 0.310312077061\n",
      "Parameter 4: 0.671438974595 +/- 0.0459208418459\n",
      "The Akaike Information Criterion of the power law model is: 1019.66099521.\n",
      "The figure-of-merit function for this model is: 505.168382171 and the fit for 567.0 dof is 0.890949527638.\n",
      "Fitting statistics: \n",
      " -- number of frequencies: 572\n",
      " -- Deviance [-2 log L] D = 2019.32199042\n",
      " -- Highest data/model outlier 2I/S = 9.17525850286\n",
      "    at frequency f_max = 3220.32809773\n",
      " -- Highest smoothed data/model outlier for smoothing factor [3] 2I/S = 6.75082116437\n",
      "    at frequency f_max = 4006.64572426\n",
      " -- Highest smoothed data/model outlier for smoothing factor [5] 2I/S = 5.39376095575\n",
      "    at frequency f_max = 3999.4973822\n",
      " -- Highest smoothed data/model outlier for smoothing factor [11] 2I/S = 5.30919771345\n",
      "    at frequency f_max = 75.057591623\n",
      " -- Summed Residuals S = 1144.00000995\n",
      " -- Expected S ~ 5720.0 +- 106.957935657\n",
      " -- KS test p-value (use with caution!) p = 0.678386549511\n",
      " -- merit function (SSE) M = 505.168382171\n",
      "The Likelihood Ratio for models pl and bpl is: LRT = 4.31905830431\n",
      "<--- self.ps len MCMC: 573\n",
      "mcobs topt: [  2.01701268  10.91242763   0.66117859]\n",
      "mcobs tcov: [[  3.3041113   11.58464322   0.91335737]\n",
      " [ 11.58464322  40.64444461   3.20574894]\n",
      " [  0.91335737   3.20574894   0.25350497]]\n",
      "The ensemble acceptance rate is: 0.64456\n",
      "The autocorrelation times are: [ 13.69669238  13.07927729   0.67279426]\n",
      "Computing Rhat. The closer to 1, the better!\n",
      "The Rhat value for parameter 0 is: 1.22616508868.\n",
      "*** HIGH Rhat! Check results! ***\n",
      "The Rhat value for parameter 1 is: 1.21592635695.\n",
      "*** HIGH Rhat! Check results! ***\n",
      "The Rhat value for parameter 2 is: 1.19169061643.\n",
      "Good Rhat. Hoorah!\n",
      "I am on parameter: 0\n",
      "I am on parameter: 1\n",
      "I am on parameter: 2\n",
      "Covariance matrix (after simulations): \n",
      "\n",
      "[[ 0.06387118  0.2606484   0.00374998]\n",
      " [ 0.2606484   1.12165753  0.01368762]\n",
      " [ 0.00374998  0.01368762  0.00222416]]\n",
      "-- Posterior Summary of Parameters: \n",
      "\n",
      "parameter \t mean \t\t sd \t\t 5% \t\t 95% \n",
      "\n",
      "---------------------------------------------\n",
      "\n",
      "theta[0] \t 2.02368674904\t0.252724949583\t1.64792135577\t2.47545143226\n",
      "\n",
      "theta[1] \t 10.9099447492\t1.05907275267\t9.32848290336\t12.79018377\n",
      "\n",
      "theta[2] \t 0.660180239349\t0.0471605198124\t0.583791621596\t0.739234367338\n",
      "\n",
      "N: 3\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "simulated srat: [1144.0000089083287, 1144.0000111752597, 1144.0000146283171, 1144.0000007186559, 1144.0000221025207, 1144.0000726338376, 1144.000033581978, 1144.0001779340037, 1144.0000000314756, 1144.0000460108481, 1144.0000193886428, 1144.000025162296, 1143.9999972681885, 1144.0000170890503, 1144.0000121751482, 1144.0000867402728, 1144.0000181526839, 1143.9999804263841, 1143.999937506569, 1144.0000371693418, 1143.9998861480487, 1143.9999950939246, 1144.0000155335615, 1144.0000230644939, 1143.9999187686753, 1144.0000227688602, 1144.0000170613482, 1143.9999952412013, 1144.0000200901359, 1143.9999662744876, 1143.9996924271063, 1144.0000230240441, 1144.0000211976944, 1143.9999956536294, 1143.9999364892697, 1144.0000431603194, 1144.0000611361952, 1144.0000027419528, 1144.0000211440085, 1143.9999988714992, 1143.9999893207323, 1143.9999973020535, 1144.0000203352697, 1144.0000096195931, 1144.0000287998357, 1144.0000203937884, 1144.0000204865541, 1144.0000557636472, 1144.0000072907105, 1144.0000285684996, 1143.9999893287509, 1144.0000318545613, 1143.9999676229509, 1144.0000117111649, 1144.0000176360022, 1144.0000172583464, 1144.000001180199, 1143.9997338394655, 1143.9999923315502, 1144.000018300067, 1144.0000061136934, 1144.000041165815, 1143.9999707376055, 1144.0000208824963, 1143.9999943794603, 1143.9999852663932, 1143.9999853189881, 1143.9999787752943, 1143.9999940646353, 1143.9999817364042, 1144.0000255154398, 1144.0000045806662, 1143.9999942164086, 1143.9999971334853, 1144.0000125842262, 1143.9999711572302, 1143.9999087914962, 1144.0000026716177, 1143.9999523359422, 1144.0000026780631, 1143.9999704530387, 1143.9999458273442, 1144.0000092324872, 1144.0000023329144, 1144.000015428674, 1144.0000092674704, 1143.9999896932934, 1143.9999975166361, 1144.0000022312299, 1143.9998506722454, 1144.0000403217666, 1144.0000059979593, 1144.0000170003173, 1144.0000910717158, 1144.0000224623509, 1144.0000288105125, 1143.9999854922858, 1143.9999811801533, 1143.9999962402148, 1143.9999667071934]\n",
      "observed srat: 1143.99996136\n",
      "p(LRT) = 0.08\n",
      "KSP(obs) = 0.786363221389\n",
      "mean(sim_ksp) = 0.657713541529\n",
      "Merit(obs) = 507.885862742\n",
      "mean(sim_merit) = 563.507536605\n",
      "Srat(obs) = 1143.99996136\n",
      "mean(sim_srat) = 1143.99999892\n",
      "Bayesian p-value for maximum power P_max =  1.0 +/- 0.0\n",
      "Bayesian p-value for deviance D =  0.56 +/- 0.049638694584\n",
      "Bayesian p-value for KS test: 0.42 +/- 0.049355850717\n",
      "Bayesian p-value for Merit function: 0.81 +/- 0.0392300904919\n",
      "Bayesian p-value for the np.sum of residuals: 0.9 +/- 0.03\n",
      "Bayesian p-value for Likelihood Ratio: 0.08 +/- 0.0271293199325\n",
      "Approximating covariance from BFGS: \n",
      "Covariance (empirical): [[ 0.01519697  0.05407622  0.00082789]\n",
      " [ 0.05407622  0.24584328  0.00112507]\n",
      " [ 0.00082789  0.00112507  0.00213984]]\n",
      "The best-fit model parameters plus errors are:\n",
      "Parameter 0: 2.01701270586 +/- 0.123275982072\n",
      "Parameter 1: 10.9124277702 +/- 0.495825856478\n",
      "Parameter 2: 0.661178569424 +/- 0.0462584352211\n",
      "The Akaike Information Criterion of the power law model is: 1017.82052436.\n",
      "The figure-of-merit function for this model is: 507.885886172 and the fit for 569.0 dof is 0.892593824556.\n",
      "Fitting statistics: \n",
      " -- number of frequencies: 572\n",
      " -- Deviance [-2 log L] D = 2023.64104872\n",
      " -- Highest data/model outlier 2I/S = 9.25528166004\n",
      "    at frequency f_max = 3220.32809773\n",
      " -- Highest smoothed data/model outlier for smoothing factor [3] 2I/S = 6.81329399934\n",
      "    at frequency f_max = 4006.64572426\n",
      " -- Highest smoothed data/model outlier for smoothing factor [5] 2I/S = 5.44365627571\n",
      "    at frequency f_max = 3999.4973822\n",
      " -- Highest smoothed data/model outlier for smoothing factor [11] 2I/S = 5.6835222886\n",
      "    at frequency f_max = 75.057591623\n",
      " -- Summed Residuals S = 1143.9999871\n",
      " -- Expected S ~ 3432.0 +- 82.8492607088\n",
      " -- KS test p-value (use with caution!) p = 0.786363112073\n",
      " -- merit function (SSE) M = 507.885886172\n",
      "<--- self.ps len MCMC: 573\n",
      "mcobs topt: [  2.01701271  10.91242777   0.66117857]\n",
      "mcobs tcov: [[ 0.01519697  0.05407622  0.00082789]\n",
      " [ 0.05407622  0.24584328  0.00112507]\n",
      " [ 0.00082789  0.00112507  0.00213984]]\n",
      "The ensemble acceptance rate is: 0.64934\n",
      "The autocorrelation times are: [ -2.0678766   -1.47617114  14.22249642]\n",
      "Computing Rhat. The closer to 1, the better!\n",
      "The Rhat value for parameter 0 is: 1.19788519044.\n",
      "Good Rhat. Hoorah!\n",
      "The Rhat value for parameter 1 is: 1.19889669364.\n",
      "Good Rhat. Hoorah!\n",
      "The Rhat value for parameter 2 is: 1.20446916009.\n",
      "*** HIGH Rhat! Check results! ***\n",
      "I am on parameter: 0\n",
      "I am on parameter: 1\n",
      "I am on parameter: 2\n",
      "Covariance matrix (after simulations): \n",
      "\n",
      "[[ 0.06702276  0.27453527  0.00378712]\n",
      " [ 0.27453527  1.1835644   0.01372363]\n",
      " [ 0.00378712  0.01372363  0.00214492]]\n",
      "-- Posterior Summary of Parameters: \n",
      "\n",
      "parameter \t mean \t\t sd \t\t 5% \t\t 95% \n",
      "\n",
      "---------------------------------------------\n",
      "\n",
      "theta[0] \t 2.02480329583\t0.258884947587\t1.63973535322\t2.48264425995\n",
      "\n",
      "theta[1] \t 10.916022338\t1.08790657972\t9.26124493658\t12.8182887699\n",
      "\n",
      "theta[2] \t 0.661619624079\t0.0463128679286\t0.584889037067\t0.736819237434\n",
      "\n",
      "N: 3\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "Gradient and/or function calls not changing!\n",
      "ninetyfiveperlim: 95\n",
      "The posterior p-value for the maximum residual power for a binning of 7.14834205934Hz is p = 0.99 +/- 0.00994987437107\n",
      "The corresponding value of the T_R statistic at frequency f = 3220.32809773 is 2I/S = 9.25528166004\n",
      "The upper limit on the T_R statistic is 2I/S = 18.7316630944\n",
      "bintemplate[0]: 4203.83496833\n",
      "The upper limit on the power at 40.0Hz for a binning of 1 is P = 295.107686604\n",
      "The upper limit on the rms amplitude at 40.0Hz for a binning of 1 is rms = 0.499035091402\n",
      "The upper limit on the power at 70.0Hz for a binning of 1 is P = 108.822584262\n",
      "The upper limit on the rms amplitude at 70.0Hz for a binning of 1 is rms = 0.303040268678\n",
      "The upper limit on the power at 100.0Hz for a binning of 1 is P = 61.7958768523\n",
      "The upper limit on the rms amplitude at 100.0Hz for a binning of 1 is rms = 0.228360283948\n",
      "The upper limit on the power at 300.0Hz for a binning of 1 is P = 20.9383784589\n",
      "The upper limit on the rms amplitude at 300.0Hz for a binning of 1 is rms = 0.132926738043\n",
      "The upper limit on the power at 500.0Hz for a binning of 1 is P = 17.8781211959\n",
      "The upper limit on the rms amplitude at 500.0Hz for a binning of 1 is rms = 0.122829239623\n",
      "The upper limit on the power at 1000.0Hz for a binning of 1 is P = 16.6155707171\n",
      "The upper limit on the rms amplitude at 1000.0Hz for a binning of 1 is rms = 0.118412747051\n",
      "ninetyfiveperlim: 95\n",
      "The posterior p-value for the maximum residual power for a binning of 21.445026178Hz is p = 1.0 +/- 0.0\n",
      "The corresponding value of the T_R statistic at frequency f = [ 4035.2390925] is 2I/S = 5.00985957456\n",
      "The upper limit on the T_R statistic is 2I/S = 8.05444611405\n",
      "bintemplate[0]: 4203.83496833\n",
      "The upper limit on the power at 40.0Hz for a binning of 3 is P = 257.004269052\n",
      "The upper limit on the rms amplitude at 40.0Hz for a binning of 3 is rms = 0.465705099507\n",
      "The upper limit on the power at 70.0Hz for a binning of 3 is P = 39.3780623413\n",
      "The upper limit on the rms amplitude at 70.0Hz for a binning of 3 is rms = 0.182292162079\n",
      "The upper limit on the power at 100.0Hz for a binning of 3 is P = 25.1315343983\n",
      "The upper limit on the rms amplitude at 100.0Hz for a binning of 3 is rms = 0.145629824918\n",
      "The upper limit on the power at 300.0Hz for a binning of 3 is P = 7.75608929325\n",
      "The upper limit on the rms amplitude at 300.0Hz for a binning of 3 is rms = 0.0809025526932\n",
      "The upper limit on the power at 500.0Hz for a binning of 3 is P = 6.46929840687\n",
      "The upper limit on the rms amplitude at 500.0Hz for a binning of 3 is rms = 0.0738872353665\n",
      "The upper limit on the power at 1000.0Hz for a binning of 3 is P = 6.01460776594\n",
      "The upper limit on the rms amplitude at 1000.0Hz for a binning of 3 is rms = 0.0712433742034\n",
      "ninetyfiveperlim: 95\n",
      "The posterior p-value for the maximum residual power for a binning of 35.7417102967Hz is p = 0.8 +/- 0.04\n",
      "The corresponding value of the T_R statistic at frequency f = [ 4006.64572426] is 2I/S = 4.42039128162\n",
      "The upper limit on the T_R statistic is 2I/S = 6.2423577297\n",
      "bintemplate[0]: 4203.83496833\n",
      "The upper limit on the power at 40.0Hz for a binning of 5 is P = 74.8253397342\n",
      "The upper limit on the rms amplitude at 40.0Hz for a binning of 5 is rms = 0.251284194909\n",
      "The upper limit on the power at 70.0Hz for a binning of 5 is P = 74.8253397342\n",
      "The upper limit on the rms amplitude at 70.0Hz for a binning of 5 is rms = 0.251284194909\n",
      "The upper limit on the power at 100.0Hz for a binning of 5 is P = 23.2995296432\n",
      "The upper limit on the rms amplitude at 100.0Hz for a binning of 5 is rms = 0.140221433211\n",
      "The upper limit on the power at 300.0Hz for a binning of 5 is P = 5.36950053309\n",
      "The upper limit on the rms amplitude at 300.0Hz for a binning of 5 is rms = 0.0673143675492\n",
      "The upper limit on the power at 500.0Hz for a binning of 5 is P = 4.58691534015\n",
      "The upper limit on the rms amplitude at 500.0Hz for a binning of 5 is rms = 0.062215871231\n",
      "The upper limit on the power at 1000.0Hz for a binning of 5 is P = 4.21921015138\n",
      "The upper limit on the rms amplitude at 1000.0Hz for a binning of 5 is rms = 0.0596700502403\n",
      "ninetyfiveperlim: 95\n",
      "The posterior p-value for the maximum residual power for a binning of 50.0383944154Hz is p = 0.22 +/- 0.0414246303544\n",
      "The corresponding value of the T_R statistic at frequency f = [ 4006.64572426] is 2I/S = 4.71461400809\n",
      "The upper limit on the T_R statistic is 2I/S = 5.3555393192\n",
      "bintemplate[0]: 4203.83496833\n",
      "The upper limit on the power at 70.0Hz for a binning of 7 is P = 33.1717021155\n",
      "The upper limit on the rms amplitude at 70.0Hz for a binning of 7 is rms = 0.167311080224\n",
      "The upper limit on the power at 100.0Hz for a binning of 7 is P = 33.1717021155\n",
      "The upper limit on the rms amplitude at 100.0Hz for a binning of 7 is rms = 0.167311080224\n",
      "The upper limit on the power at 300.0Hz for a binning of 7 is P = 4.55063122318\n",
      "The upper limit on the rms amplitude at 300.0Hz for a binning of 7 is rms = 0.0619693079278\n",
      "The upper limit on the power at 500.0Hz for a binning of 7 is P = 3.65247607933\n",
      "The upper limit on the rms amplitude at 500.0Hz for a binning of 7 is rms = 0.0555180897978\n",
      "The upper limit on the power at 1000.0Hz for a binning of 7 is P = 3.33988754909\n",
      "The upper limit on the rms amplitude at 1000.0Hz for a binning of 7 is rms = 0.0530892692129\n",
      "ninetyfiveperlim: 95\n",
      "The posterior p-value for the maximum residual power for a binning of 71.4834205934Hz is p = 0.32 +/- 0.0466476151588\n",
      "The corresponding value of the T_R statistic at frequency f = [ 4006.64572426] is 2I/S = 3.85708764422\n",
      "The upper limit on the T_R statistic is 2I/S = 4.71225070834\n",
      "bintemplate[0]: 4203.83496833\n",
      "The upper limit on the power at 100.0Hz for a binning of 10 is P = 14.8960011873\n",
      "The upper limit on the rms amplitude at 100.0Hz for a binning of 10 is rms = 0.112118085682\n",
      "The upper limit on the power at 300.0Hz for a binning of 10 is P = 3.43286270328\n",
      "The upper limit on the rms amplitude at 300.0Hz for a binning of 10 is rms = 0.0538231414105\n",
      "The upper limit on the power at 500.0Hz for a binning of 10 is P = 2.98562288038\n",
      "The upper limit on the rms amplitude at 500.0Hz for a binning of 10 is rms = 0.0501947505146\n",
      "The upper limit on the power at 1000.0Hz for a binning of 10 is P = 2.70300917177\n",
      "The upper limit on the rms amplitude at 1000.0Hz for a binning of 10 is rms = 0.0477600292935\n",
      "ninetyfiveperlim: 95\n",
      "The posterior p-value for the maximum residual power for a binning of 107.22513089Hz is p = 0.14 +/- 0.0346987031458\n",
      "The corresponding value of the T_R statistic at frequency f = [ 3970.90401396] is 2I/S = 3.52470149813\n",
      "The upper limit on the T_R statistic is 2I/S = 3.85622663015\n",
      "bintemplate[0]: 4203.83496833\n",
      "The upper limit on the power at 300.0Hz for a binning of 15 is P = 2.77509182147\n",
      "The upper limit on the rms amplitude at 300.0Hz for a binning of 15 is rms = 0.048392660997\n",
      "The upper limit on the power at 500.0Hz for a binning of 15 is P = 2.04331873935\n",
      "The upper limit on the rms amplitude at 500.0Hz for a binning of 15 is rms = 0.0415249275889\n",
      "The upper limit on the power at 1000.0Hz for a binning of 15 is P = 1.84609849998\n",
      "The upper limit on the rms amplitude at 1000.0Hz for a binning of 15 is rms = 0.0394701029834\n",
      "ninetyfiveperlim: 95\n",
      "The posterior p-value for the maximum residual power for a binning of 142.966841187Hz is p = 0.11 +/- 0.0312889756943\n",
      "The corresponding value of the T_R statistic at frequency f = [ 3863.67888307] is 2I/S = 3.3291622105\n",
      "The upper limit on the T_R statistic is 2I/S = 3.44695393724\n",
      "bintemplate[0]: 4203.83496833\n",
      "The upper limit on the power at 300.0Hz for a binning of 20 is P = 1.83139198351\n",
      "The upper limit on the rms amplitude at 300.0Hz for a binning of 20 is rms = 0.0393125739057\n",
      "The upper limit on the power at 500.0Hz for a binning of 20 is P = 1.59279478427\n",
      "The upper limit on the rms amplitude at 500.0Hz for a binning of 20 is rms = 0.0366623869877\n",
      "The upper limit on the power at 1000.0Hz for a binning of 20 is P = 1.44910569103\n",
      "The upper limit on the rms amplitude at 1000.0Hz for a binning of 20 is rms = 0.034969615395\n",
      "ninetyfiveperlim: 95\n",
      "The posterior p-value for the maximum residual power for a binning of 214.45026178Hz is p = 0.01 +/- 0.00994987437107\n",
      "The corresponding value of the T_R statistic at frequency f = [ 3863.67888307] is 2I/S = 3.50498784535\n",
      "The upper limit on the T_R statistic is 2I/S = 3.27889529218\n",
      "bintemplate[0]: 4203.83496833\n",
      "The upper limit on the power at 300.0Hz for a binning of 30 is P = 1.91197120449\n",
      "The upper limit on the rms amplitude at 300.0Hz for a binning of 30 is rms = 0.0401681193198\n",
      "The upper limit on the power at 500.0Hz for a binning of 30 is P = 1.40779723431\n",
      "The upper limit on the rms amplitude at 500.0Hz for a binning of 30 is rms = 0.0344675868567\n",
      "The upper limit on the power at 1000.0Hz for a binning of 30 is P = 1.28079712729\n",
      "The upper limit on the rms amplitude at 1000.0Hz for a binning of 30 is rms = 0.0328761533278\n",
      "ninetyfiveperlim: 95\n",
      "The posterior p-value for the maximum residual power for a binning of 357.417102967Hz is p = 1.0 +/- 0.0\n",
      "The corresponding value of the T_R statistic at frequency f = [ 1075.82547993] is 2I/S = 2.14404856044\n",
      "The upper limit on the T_R statistic is 2I/S = 2.75511378582\n",
      "bintemplate[0]: 4203.83496833\n",
      "The upper limit on the power at 500.0Hz for a binning of 50 is P = 0.875131569532\n",
      "The upper limit on the rms amplitude at 500.0Hz for a binning of 50 is rms = 0.027175497302\n",
      "The upper limit on the power at 1000.0Hz for a binning of 50 is P = 0.767235607359\n",
      "The upper limit on the rms amplitude at 1000.0Hz for a binning of 50 is rms = 0.0254451608119\n",
      "ninetyfiveperlim: 95\n",
      "The posterior p-value for the maximum residual power for a binning of 500.383944154Hz is p = 0.79 +/- 0.0407308237088\n",
      "The corresponding value of the T_R statistic at frequency f = [ 3506.2617801] is 2I/S = 2.23733965908\n",
      "The upper limit on the T_R statistic is 2I/S = 2.54856520588\n",
      "bintemplate[0]: 4203.83496833\n",
      "The upper limit on the power at 1000.0Hz for a binning of 70 is P = 0.584595171485\n",
      "The upper limit on the rms amplitude at 1000.0Hz for a binning of 70 is rms = 0.0222110166052\n",
      "ninetyfiveperlim: 95\n",
      "The posterior p-value for the maximum residual power for a binning of 714.834205934Hz is p = 1.0 +/- 0.0\n",
      "The corresponding value of the T_R statistic at frequency f = [ 2862.91099476] is 2I/S = 1.90786275145\n",
      "The upper limit on the T_R statistic is 2I/S = 2.37777124581\n",
      "bintemplate[0]: 4203.83496833\n",
      "The upper limit on the power at 1000.0Hz for a binning of 100 is P = 0.383835597587\n",
      "The upper limit on the rms amplitude at 1000.0Hz for a binning of 100 is rms = 0.0179975525197\n",
      "ninetyfiveperlim: 95\n",
      "The posterior p-value for the maximum residual power for a binning of 1429.66841187Hz is p = 0.94 +/- 0.0237486841741\n",
      "The corresponding value of the T_R statistic at frequency f = [ 1433.2425829] is 2I/S = 1.86442883073\n",
      "The upper limit on the T_R statistic is 2I/S = 2.19630050947\n",
      "bintemplate[0]: 4203.83496833\n",
      "Bayesian p-value for maximum power P_max =  0.99 +/- 0.00994987437107\n",
      "Bayesian p-value for maximum power P_max =  0.68 +/- 0.0466476151588\n",
      "Bayesian p-value for maximum power P_max =  0.76 +/- 0.0427083130081\n",
      "Bayesian p-value for maximum power P_max =  0.42 +/- 0.049355850717\n",
      "Bayesian p-value for deviance D =  0.49 +/- 0.0499899989998\n",
      "Bayesian p-value for KS test: 0.47 +/- 0.0499099188539\n",
      "Bayesian p-value for Merit function: 0.89 +/- 0.0312889756943\n",
      "Bayesian p-value for the np.sum of residuals: 0.82 +/- 0.0384187454246\n"
     ]
    }
   ],
   "source": [
    "namestr = \"%s_%.3f_test\"%(bid, bst) ## a string identifier for output files\n",
    "nchain = 500 ## number of emcee walkers\n",
    "niter = 100 ## number of iterations in the Markov chain\n",
    "nsim = 100 ## number of simulations\n",
    "\n",
    "m = 1 ## periodogram not averaged\n",
    "fitmethod = \"bfgs\" ## use BFGS for optimization\n",
    "\n",
    "burst.bayesian_analysis(namestr = namestr,\n",
    "                       nchain = nchain,\n",
    "                       niter = niter,\n",
    "                       nsim = nsim,\n",
    "                       m = 1, fitmethod = fitmethod)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then it goes through the entire analysis above.\n",
    "\n",
    "## Running Many Bursts\n",
    "\n",
    "I've provided you with two files:\n",
    "* `sgr1550_burstdata.dat` has some burst IDs, start times and durations as specified above\n",
    "* `090122037a_tte_combined.dat` contains the photon arrival times and energies needed to run the bursts in the file above.\n",
    "\n",
    "The following defines some (simple) code that will read in `sgr1550_burstdata.dat`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_burstdata(filename, datadir=\"./\"):\n",
    "    \"\"\"\n",
    "    Run Bayesian QPO search on all bursts in file filename. \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    filename: string\n",
    "        Name of a file with minimal burst data. Needs to have columns:\n",
    "        1. ObsID\n",
    "        2. MET trigger time\n",
    "        3. Seconds since trigger\n",
    "        4. Burst duration in seconds\n",
    "        Note that this is the way my file is currently set up. You can change \n",
    "        this by changing the indices of the columns read out below.\n",
    "    \n",
    "    datadir: string\n",
    "        Directory where the data (including the file in filename) is located.\n",
    "    \"\"\"\n",
    "    \n",
    "    ## read in data\n",
    "    ## type needs to be string, otherwise code fails on ObsID column, \n",
    "    ## which doesn't purely consist of numbers\n",
    "    data  = np.loadtxt(datadir+filename, dtype=np.string_)\n",
    "    \n",
    "    ## ObsIDs are in first column, need to remain string\n",
    "    obsids = data[:,0]\n",
    "    \n",
    "    ## trigger time is in second column, should be float\n",
    "    trigtime = data[:,1].astype(\"float64\")\n",
    "    \n",
    "    ## start time in seconds since trigger is in third column,\n",
    "    ## should be float\n",
    "    bstart = data[:,2].astype(\"float64\")\n",
    "    \n",
    "    ## burst duration in seconds is in fourth column,\n",
    "    ## should be float\n",
    "    blength = data[:,3].astype(\"float64\")\n",
    "    \n",
    "    \n",
    "    return obsids, trigtime, bstart, blength\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now run the function above on the example file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## now run the function above on the example file\n",
    "obsids, trigtime, bstart, blength = run_bursts(\"sgr1550_burstdata.dat\", datadir=\"../data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## unique set of ObsIDs\n",
    "obsid_set = np.unique(obsids)\n",
    "\n",
    "for o in obsid_set:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['090122037a'], \n",
       "      dtype='|S13')"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tte = np.loadtxt(\"090122037a_tte_combined.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -28.54545999,  -28.545286  ,  -28.544788  , ...,  300.88343799,\n",
       "        300.88389599,  300.884186  ])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
